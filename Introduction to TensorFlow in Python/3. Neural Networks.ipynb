{"cells":[{"source":"# What is a Neural Network?\n![image-4](image-4.png)\n\nSo how do we get from a linear regression to a neural network? By adding a hidden layer, which, in this case, consists of two nodes. \n- Each hidden layer node takes our two inputs, multiplies them by their respective weights, and sums them together. \n- We also typically pass the hidden layer output to an activation function.\n- **This entire process of generating a prediction is referred to as forward propagation.**","metadata":{},"cell_type":"markdown","id":"cc5e8304-e0f2-4eb6-b319-cbea626b60a7"},{"source":"## Dense layers\n![image-5](image-5.png)\n\n In the neural network graph, we have applied a particular type of hidden layer called a dense layer. **A dense layer applies weights to all nodes from the previous layer.**","metadata":{},"cell_type":"markdown","id":"2d8d2425-5ec9-4906-8461-cec7c2c57185"},{"source":"# A simple dense layer\nimport tensorflow as tf\n\n# Define inputs (features)\ninputs = tf.constant([[1.0,35.0]])\ninputs","metadata":{"executionTime":133,"lastSuccessfullyExecutedCode":"# A simple dense layer\nimport tensorflow as tf\n\n# Define inputs (features)\ninputs = tf.constant([[1.0,35.0]])\ninputs"},"cell_type":"code","id":"6dd0f607-7339-456b-a970-d72a576a41a4","execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":"2023-05-22 09:15:12.237340: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2023-05-22 09:15:12.237363: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n2023-05-22 09:15:13.750125: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n2023-05-22 09:15:13.750147: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n2023-05-22 09:15:13.750163: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (c140639e-255a-49cd-ab04-8a39251c1610): /proc/driver/nvidia/version does not exist\n2023-05-22 09:15:13.750415: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"},{"output_type":"execute_result","execution_count":1,"data":{"text/plain":"<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[ 1., 35.]], dtype=float32)>"},"metadata":{}}]},{"source":"# Define weights\nweights = tf.Variable([[-0.05],[-0.01]])\nweights","metadata":{"executionTime":95,"lastSuccessfullyExecutedCode":"# Define weights\nweights = tf.Variable([[-0.05],[-0.01]])\nweights"},"cell_type":"code","id":"fe55aaf1-b4ef-4619-b170-427c5ee22031","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"<tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\narray([[-0.05],\n       [-0.01]], dtype=float32)>"},"metadata":{}}]},{"source":"# Define the bias\nbias = tf.Variable([0.5])\nbias","metadata":{"executionTime":110,"lastSuccessfullyExecutedCode":"# Define the bias\nbias = tf.Variable([0.5])\nbias"},"cell_type":"code","id":"b29b687a-294d-4e67-8108-466a757942a7","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.5], dtype=float32)>"},"metadata":{}}]},{"source":"# Multiply inputs(features) by the weights\nproduct = tf.matmul(inputs, weights)\nproduct","metadata":{"executionTime":91,"lastSuccessfullyExecutedCode":"# Multiply inputs(features) by the weights\nproduct = tf.matmul(inputs, weights)\nproduct"},"cell_type":"code","id":"4244427a-3142-42af-98c8-874fc71e7de4","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-0.4]], dtype=float32)>"},"metadata":{}}]},{"source":"# Define dense layer -- sigmoid(takes any input value and returns a value between 0 and 1)\ndense = tf.keras.activations.sigmoid(product+bias)\ndense","metadata":{"executionTime":105,"lastSuccessfullyExecutedCode":"# Define dense layer -- sigmoid(takes any input value and returns a value between 0 and 1)\ndense = tf.keras.activations.sigmoid(product+bias)\ndense"},"cell_type":"code","id":"75686ba9-56df-4f87-8ebb-7796e0741ca1","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.5249792]], dtype=float32)>"},"metadata":{}}]},{"source":"The neural network looks like:\n![image-6](image-6.png)\n","metadata":{},"cell_type":"markdown","id":"c31f3597-a090-45ce-bb2c-d208274e5be2"},{"source":"## Type 1: The linear algebra of dense layers","metadata":{},"cell_type":"markdown","id":"d81578cb-4f97-40a5-b698-a0390bc728d5"},{"source":"![image-7](image-7.png)\n\nThe input layer contains 3 features -- education, marital status, and age -- which are available as `borrower_features`. The hidden layer contains 2 nodes and the output layer contains a single node.\n\nFor each layer, you will take the previous layer as an input, initialize a set of weights, compute the product of the inputs and weights, and then apply an activation function. ","metadata":{},"cell_type":"markdown","id":"8ebb86ed-76ec-4370-9b8b-ef5850ceb6e0"},{"source":"# Initializing input\nborrower_features = tf.Variable([[3.0, 1.0, 21.0]])\n\n# Initializing weight and bias for dense layer\nweight1 = tf.ones([3,2])\nbias1 = tf.Variable([1.0])","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# Initializing input\nborrower_features = tf.Variable([[3.0, 1.0, 21.0]])\n\n# Initializing weight and bias for dense layer\nweight1 = tf.ones([3,2])\nbias1 = tf.Variable([1.0])"},"cell_type":"code","id":"253d17c6-3a77-4090-a88f-a397e7a8516f","execution_count":6,"outputs":[]},{"source":"# Calculating for dense layer\nproduct = tf.matmul(borrower_features, weight1)\ndense1 = tf.keras.activations.sigmoid(product+bias1)\ndense1","metadata":{"executionTime":104,"lastSuccessfullyExecutedCode":"# Calculating for dense layer\nproduct = tf.matmul(borrower_features, weight1)\ndense1 = tf.keras.activations.sigmoid(product+bias1)\ndense1"},"cell_type":"code","id":"afad0b81-ee29-4288-9ce9-722bbb3514fa","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[1., 1.]], dtype=float32)>"},"metadata":{}}]},{"source":"**For dense layer**\n\ndense1 = sigmoid [Î£(inputs x weights) + bias]\n\n![image-11.png](image-11.png)\n","metadata":{},"cell_type":"markdown","id":"e9893982-04ce-4f2e-8ecd-235ebddb7b80"},{"source":"# Initializing weight and bias for output layer\nweight2 = tf.ones([2,1])\nbias2 = tf.Variable([1.0])\n\n# Calculating output\nproduct = tf.matmul(dense1,weight2)\noutput = tf.keras.activations.sigmoid(product+bias2)\n\nprint(\"Predicted output:\", output.numpy())","metadata":{"executionTime":84,"lastSuccessfullyExecutedCode":"# Initializing weight and bias for output layer\nweight2 = tf.ones([2,1])\nbias2 = tf.Variable([1.0])\n\n# Calculating output\nproduct = tf.matmul(dense1,weight2)\noutput = tf.keras.activations.sigmoid(product+bias2)\n\nprint(\"Predicted output:\", output.numpy())"},"cell_type":"code","id":"473f64d0-c135-44f0-b196-5f05df1efd78","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":"Predicted output: [[0.95257413]]\n"}]},{"source":"## Type 2: Using the dense layer operation","metadata":{},"cell_type":"markdown","id":"c0ed4c0d-5e39-410b-a76c-762a2d8aa106"},{"source":"![image-8](image-8.png)\n\nConstruct the network above, which has 2 hidden layers and 10 features. \n- To construct this network, we'll need to define three dense layers, each of which takes the previous layer as an input, multiplies it by weights, and applies an activation function.","metadata":{},"cell_type":"markdown","id":"7b44d9eb-bd4c-49eb-a5ce-8a34a044b9c2"},{"source":"# Instantiate input with 100x10 tensors i.e 10 features\nborrower_features = tf.Variable([[6.96469188e-01, 2.86139339e-01, 2.26851448e-01, 5.51314771e-01,\n        7.19468951e-01, 4.23106462e-01, 9.80764210e-01, 6.84829712e-01,\n        4.80931908e-01, 3.92117530e-01],\n       [3.43178004e-01, 7.29049683e-01, 4.38572258e-01, 5.96778952e-02,\n        3.98044258e-01, 7.37995386e-01, 1.82491735e-01, 1.75451756e-01,\n        5.31551361e-01, 5.31827569e-01],\n       [6.34400964e-01, 8.49431813e-01, 7.24455297e-01, 6.11023486e-01,\n        7.22443402e-01, 3.22958916e-01, 3.61788660e-01, 2.28263229e-01,\n        2.93714046e-01, 6.30976140e-01],\n       [9.21049416e-02, 4.33701187e-01, 4.30862755e-01, 4.93685097e-01,\n        4.25830305e-01, 3.12261224e-01, 4.26351309e-01, 8.93389165e-01,\n        9.44160044e-01, 5.01836658e-01],\n       [6.23952925e-01, 1.15618393e-01, 3.17285478e-01, 4.14826214e-01,\n        8.66309166e-01, 2.50455379e-01, 4.83034253e-01, 9.85559762e-01,\n        5.19485116e-01, 6.12894535e-01],\n       [1.20628662e-01, 8.26340795e-01, 6.03060126e-01, 5.45068026e-01,\n        3.42763841e-01, 3.04120779e-01, 4.17022198e-01, 6.81300759e-01,\n        8.75456870e-01, 5.10422349e-01],\n       [6.69313788e-01, 5.85936546e-01, 6.24903500e-01, 6.74689054e-01,\n        8.42342436e-01, 8.31949860e-02, 7.63682842e-01, 2.43666381e-01,\n        1.94222957e-01, 5.72456956e-01],\n       [9.57125202e-02, 8.85326803e-01, 6.27248943e-01, 7.23416328e-01,\n        1.61292069e-02, 5.94431877e-01, 5.56785166e-01, 1.58959642e-01,\n        1.53070509e-01, 6.95529521e-01],\n       [3.18766415e-01, 6.91970289e-01, 5.54383278e-01, 3.88950586e-01,\n        9.25132513e-01, 8.41669977e-01, 3.57397556e-01, 4.35914621e-02,\n        3.04768085e-01, 3.98185670e-01],\n       [7.04958856e-01, 9.95358467e-01, 3.55914861e-01, 7.62547791e-01,\n        5.93176901e-01, 6.91701770e-01, 1.51127458e-01, 3.98876280e-01,\n        2.40855902e-01, 3.43456000e-01],\n       [5.13128161e-01, 6.66624546e-01, 1.05908483e-01, 1.30894944e-01,\n        3.21980596e-01, 6.61564350e-01, 8.46506238e-01, 5.53257346e-01,\n        8.54452491e-01, 3.84837806e-01],\n       [3.16787899e-01, 3.54264677e-01, 1.71081826e-01, 8.29112649e-01,\n        3.38670850e-01, 5.52370071e-01, 5.78551471e-01, 5.21533072e-01,\n        2.68806447e-03, 9.88345444e-01],\n       [9.05341566e-01, 2.07635865e-01, 2.92489409e-01, 5.20010173e-01,\n        9.01911378e-01, 9.83630896e-01, 2.57542074e-01, 5.64359069e-01,\n        8.06968689e-01, 3.94370049e-01],\n       [7.31073022e-01, 1.61069021e-01, 6.00698590e-01, 8.65864456e-01,\n        9.83521581e-01, 7.93657899e-02, 4.28347290e-01, 2.04542860e-01,\n        4.50636476e-01, 5.47763586e-01],\n       [9.33267102e-02, 2.96860784e-01, 9.27584231e-01, 5.69003761e-01,\n        4.57412004e-01, 7.53525972e-01, 7.41862178e-01, 4.85790335e-02,\n        7.08697379e-01, 8.39243352e-01],\n       [1.65937886e-01, 7.80997932e-01, 2.86536604e-01, 3.06469738e-01,\n        6.65261447e-01, 1.11392170e-01, 6.64872468e-01, 8.87856781e-01,\n        6.96311295e-01, 4.40327883e-01],\n       [4.38214391e-01, 7.65096068e-01, 5.65641999e-01, 8.49041641e-02,\n        5.82671106e-01, 8.14843714e-01, 3.37066382e-01, 9.27576602e-01,\n        7.50716984e-01, 5.74063838e-01],\n       [7.51644015e-01, 7.91489631e-02, 8.59389067e-01, 8.21504116e-01,\n        9.09871638e-01, 1.28631204e-01, 8.17800835e-02, 1.38415575e-01,\n        3.99378717e-01, 4.24306870e-01],\n       [5.62218368e-01, 1.22243546e-01, 2.01399505e-01, 8.11644375e-01,\n        4.67987567e-01, 8.07938218e-01, 7.42637832e-03, 5.51592708e-01,\n        9.31932151e-01, 5.82175434e-01],\n       [2.06095725e-01, 7.17757583e-01, 3.78985852e-01, 6.68383956e-01,\n        2.93197222e-02, 6.35900378e-01, 3.21979336e-02, 7.44780660e-01,\n        4.72912997e-01, 1.21754356e-01],\n       [5.42635918e-01, 6.67744428e-02, 6.53364897e-01, 9.96086299e-01,\n        7.69397318e-01, 5.73774099e-01, 1.02635257e-01, 6.99834049e-01,\n        6.61167860e-01, 4.90971319e-02],\n       [7.92299330e-01, 5.18716574e-01, 4.25867707e-01, 7.88187146e-01,\n        4.11569238e-01, 4.81026262e-01, 1.81628838e-01, 3.21318895e-01,\n        8.45533013e-01, 1.86903745e-01],\n       [4.17291075e-01, 9.89034534e-01, 2.36599818e-01, 9.16832328e-01,\n        9.18397486e-01, 9.12963450e-02, 4.63652730e-01, 5.02216339e-01,\n        3.13668936e-01, 4.73395362e-02],\n       [2.41685644e-01, 9.55296382e-02, 2.38249913e-01, 8.07791114e-01,\n        8.94978285e-01, 4.32228930e-02, 3.01946849e-01, 9.80582178e-01,\n        5.39504826e-01, 6.26309335e-01],\n       [5.54540846e-03, 4.84909445e-01, 9.88328516e-01, 3.75185519e-01,\n        9.70381573e-02, 4.61908758e-01, 9.63004470e-01, 3.41830611e-01,\n        7.98922718e-01, 7.98846304e-01],\n       [2.08248302e-01, 4.43367690e-01, 7.15601265e-01, 4.10519779e-01,\n        1.91006958e-01, 9.67494309e-01, 6.50750339e-01, 8.65459859e-01,\n        2.52423584e-02, 2.66905814e-01],\n       [5.02071083e-01, 6.74486384e-02, 9.93033290e-01, 2.36462399e-01,\n        3.74292195e-01, 2.14011908e-01, 1.05445869e-01, 2.32479781e-01,\n        3.00610125e-01, 6.34442270e-01],\n       [2.81234771e-01, 3.62276763e-01, 5.94284385e-03, 3.65719140e-01,\n        5.33885956e-01, 1.62015840e-01, 5.97433090e-01, 2.93152481e-01,\n        6.32050514e-01, 2.61966046e-02],\n       [8.87593448e-01, 1.61186308e-02, 1.26958027e-01, 7.77162433e-01,\n        4.58952338e-02, 7.10998714e-01, 9.71046150e-01, 8.71682942e-01,\n        7.10161626e-01, 9.58509743e-01],\n       [4.29813325e-01, 8.72878909e-01, 3.55957657e-01, 9.29763675e-01,\n        1.48777649e-01, 9.40029025e-01, 8.32716227e-01, 8.46054852e-01,\n        1.23923011e-01, 5.96486926e-01],\n       [1.63924806e-02, 7.21184373e-01, 7.73751410e-03, 8.48222747e-02,\n        2.25498408e-01, 8.75124514e-01, 3.63576323e-01, 5.39959908e-01,\n        5.68103194e-01, 2.25463361e-01],\n       [5.72146773e-01, 6.60951793e-01, 2.98245400e-01, 4.18626845e-01,\n        4.53088939e-01, 9.32350636e-01, 5.87493777e-01, 9.48252380e-01,\n        5.56034744e-01, 5.00561416e-01],\n       [3.53221106e-03, 4.80889052e-01, 9.27455008e-01, 1.98365688e-01,\n        5.20911328e-02, 4.06778902e-01, 3.72396469e-01, 8.57153058e-01,\n        2.66111158e-02, 9.20149207e-01],\n       [6.80903018e-01, 9.04226005e-01, 6.07529044e-01, 8.11953306e-01,\n        3.35543871e-01, 3.49566221e-01, 3.89874220e-01, 7.54797101e-01,\n        3.69291186e-01, 2.42219806e-01],\n       [9.37668383e-01, 9.08011079e-01, 3.48797321e-01, 6.34638071e-01,\n        2.73842216e-01, 2.06115127e-01, 3.36339533e-01, 3.27099890e-01,\n        8.82276118e-01, 8.22303832e-01],\n       [7.09623218e-01, 9.59345222e-01, 4.22543347e-01, 2.45033041e-01,\n        1.17398441e-01, 3.01053345e-01, 1.45263731e-01, 9.21861008e-02,\n        6.02932215e-01, 3.64187449e-01],\n       [5.64570367e-01, 1.91335723e-01, 6.76905870e-01, 2.15505451e-01,\n        2.78023601e-01, 7.41760433e-01, 5.59737921e-01, 3.34836423e-01,\n        5.42988777e-01, 6.93984687e-01],\n       [9.12132144e-01, 5.80713212e-01, 2.32686386e-01, 7.46697605e-01,\n        7.77769029e-01, 2.00401321e-01, 8.20574224e-01, 4.64934856e-01,\n        7.79766679e-01, 2.37478226e-01],\n       [3.32580268e-01, 9.53697145e-01, 6.57815099e-01, 7.72877812e-01,\n        6.88374341e-01, 2.04304114e-01, 4.70688760e-01, 8.08963895e-01,\n        6.75035119e-01, 6.02788571e-03],\n       [8.74077454e-02, 3.46794724e-01, 9.44365561e-01, 4.91190493e-01,\n        2.70176262e-01, 3.60423714e-01, 2.10652635e-01, 4.21200067e-01,\n        2.18035445e-01, 8.45752478e-01],\n       [4.56270605e-01, 2.79802024e-01, 9.32891667e-01, 3.14351350e-01,\n        9.09714639e-01, 4.34180908e-02, 7.07115054e-01, 4.83889043e-01,\n        4.44221050e-01, 3.63233462e-02],\n       [4.06831913e-02, 3.32753628e-01, 9.47119534e-01, 6.17659986e-01,\n        3.68874848e-01, 6.11977041e-01, 2.06131533e-01, 1.65066436e-01,\n        3.61817271e-01, 8.63353372e-01],\n       [5.09401739e-01, 2.96901524e-01, 9.50251639e-01, 8.15966070e-01,\n        3.22973937e-01, 9.72098231e-01, 9.87351120e-01, 4.08660144e-01,\n        6.55923128e-01, 4.05653208e-01],\n       [2.57348120e-01, 8.26526731e-02, 2.63610333e-01, 2.71479845e-01,\n        3.98639083e-01, 1.84886038e-01, 9.53818381e-01, 1.02879882e-01,\n        6.25208557e-01, 4.41697389e-01],\n       [4.23518062e-01, 3.71991783e-01, 8.68314683e-01, 2.80476987e-01,\n        2.05761567e-02, 9.18097019e-01, 8.64480257e-01, 2.76901782e-01,\n        5.23487568e-01, 1.09088197e-01],\n       [9.34270695e-02, 8.37466121e-01, 4.10265714e-01, 6.61716521e-01,\n        9.43200588e-01, 2.45130599e-01, 1.31598311e-02, 2.41484065e-02,\n        7.09385693e-01, 9.24551904e-01],\n       [4.67330277e-01, 3.75109136e-01, 5.42860448e-01, 8.58916819e-01,\n        6.52153850e-01, 2.32979894e-01, 7.74580181e-01, 1.34613499e-01,\n        1.65559977e-01, 6.12682283e-01],\n       [2.38783404e-01, 7.04778552e-01, 3.49518538e-01, 2.77423948e-01,\n        9.98918414e-01, 4.06161249e-02, 6.45822525e-01, 3.86995859e-02,\n        7.60210276e-01, 2.30089962e-01],\n       [8.98318663e-02, 6.48449719e-01, 7.32601225e-01, 6.78095341e-01,\n        5.19009456e-02, 2.94306934e-01, 4.51088339e-01, 2.87103295e-01,\n        8.10513437e-01, 1.31115109e-01],\n       [6.12179339e-01, 9.88214970e-01, 9.02556539e-01, 2.22157061e-01,\n        8.18876142e-05, 9.80597317e-01, 8.82712960e-01, 9.19472456e-01,\n        4.15503561e-01, 7.44615436e-01],\n       [2.12831497e-01, 3.92304063e-01, 8.51548076e-01, 1.27612218e-01,\n        8.93865347e-01, 4.96507972e-01, 4.26095665e-01, 3.05646390e-01,\n        9.16848779e-01, 5.17623484e-01],\n       [8.04026365e-01, 8.57651770e-01, 9.22382355e-01, 3.03380728e-01,\n        3.39810848e-01, 5.95073879e-01, 4.41324145e-01, 9.32842553e-01,\n        3.97564054e-01, 4.77778047e-01],\n       [6.17186069e-01, 4.04739499e-01, 9.92478430e-01, 9.88512859e-02,\n        2.20603317e-01, 3.22655141e-01, 1.47722840e-01, 2.84219235e-01,\n        7.79245317e-01, 5.22891998e-01],\n       [3.39536369e-02, 9.82622564e-01, 6.16006494e-01, 5.89394793e-02,\n        6.61168754e-01, 3.78369361e-01, 1.35673299e-01, 5.63664615e-01,\n        7.27079928e-01, 6.71126604e-01],\n       [2.47513160e-01, 5.24866223e-01, 5.37663460e-01, 7.16803372e-01,\n        3.59867334e-01, 7.97732592e-01, 6.27921820e-01, 3.83316055e-02,\n        5.46479046e-01, 8.61912072e-01],\n       [5.67574143e-01, 1.75828263e-01, 5.10376394e-01, 7.56945848e-01,\n        1.10105194e-01, 8.17099094e-01, 1.67481646e-01, 5.34076512e-01,\n        3.85743469e-01, 2.48623773e-01],\n       [6.47432506e-01, 3.73921096e-02, 7.60045826e-01, 5.26940644e-01,\n        8.75771224e-01, 5.20718336e-01, 3.50331701e-02, 1.43600971e-01,\n        7.95604587e-01, 4.91976053e-01],\n       [4.41879272e-01, 3.18434775e-01, 2.84549206e-01, 9.65886295e-01,\n        4.32969332e-01, 8.84003043e-01, 6.48163140e-01, 8.58427644e-01,\n        8.52449536e-01, 9.56312001e-01],\n       [6.97942257e-01, 8.05396914e-01, 7.33127892e-01, 6.05226815e-01,\n        7.17354119e-01, 7.15750396e-01, 4.09077927e-02, 5.16110837e-01,\n        7.92651355e-01, 2.42962182e-01],\n       [4.65147972e-01, 4.34985697e-01, 4.02787179e-01, 1.21839531e-01,\n        5.25711536e-01, 4.46248353e-01, 6.63392782e-01, 5.49413085e-01,\n        2.75429301e-02, 3.19179893e-02],\n       [7.01359808e-01, 7.07581103e-01, 9.59939122e-01, 8.76704693e-01,\n        4.68059659e-01, 6.25906527e-01, 4.57181722e-01, 2.22946241e-01,\n        3.76677006e-01, 1.03884235e-01],\n       [6.66527092e-01, 1.92030147e-01, 4.75467801e-01, 9.67436612e-01,\n        3.16689312e-02, 1.51729956e-01, 2.98579186e-01, 9.41806972e-01,\n        9.08841789e-01, 1.62000835e-01],\n       [9.81117785e-01, 7.50747502e-01, 5.39977074e-01, 9.31702912e-01,\n        8.80607128e-01, 3.91316503e-01, 6.56343222e-01, 6.47385120e-01,\n        3.26968193e-01, 1.79390177e-01],\n       [4.66809869e-01, 2.63281047e-01, 3.55065137e-01, 9.54143941e-01,\n        4.61137861e-01, 6.84891462e-01, 3.36229891e-01, 9.95861053e-01,\n        6.58767581e-01, 1.96009472e-01],\n       [9.81839970e-02, 9.43180561e-01, 9.44777846e-01, 6.21328354e-01,\n        1.69914998e-02, 2.25534886e-01, 8.01276803e-01, 8.75459850e-01,\n        4.53989804e-01, 3.65520626e-01],\n       [2.74224997e-01, 1.16970517e-01, 1.15744539e-01, 9.52602684e-01,\n        8.08626115e-01, 1.64779365e-01, 2.07050055e-01, 6.55551553e-01,\n        7.64664233e-01, 8.10314834e-01],\n       [1.63337693e-01, 9.84128296e-01, 2.27802068e-01, 5.89415431e-01,\n        5.87615728e-01, 9.67361867e-01, 6.57667458e-01, 5.84904253e-01,\n        5.18772602e-01, 7.64657557e-01],\n       [1.06055260e-01, 2.09190114e-03, 9.52488840e-01, 4.98657674e-01,\n        3.28335375e-01, 3.68053257e-01, 8.03843319e-01, 3.82370204e-01,\n        7.70169199e-01, 4.40461993e-01],\n       [8.44077468e-01, 7.62040615e-02, 4.81128335e-01, 4.66849715e-01,\n        2.64327973e-01, 9.43614721e-01, 9.05028462e-01, 4.43596303e-01,\n        9.71596092e-02, 2.06783146e-01],\n       [2.71491826e-01, 4.84219760e-01, 3.38377118e-01, 7.74136066e-01,\n        4.76026595e-01, 8.70370507e-01, 9.95781779e-01, 2.19835952e-01,\n        6.11671388e-01, 8.47502291e-01],\n       [9.45236623e-01, 2.90086418e-01, 7.27042735e-01, 1.50161488e-02,\n        8.79142463e-01, 6.39385507e-02, 7.33395398e-01, 9.94610369e-01,\n        5.01189768e-01, 2.09333986e-01],\n       [5.94643593e-01, 6.24149978e-01, 6.68072760e-01, 1.72611743e-01,\n        8.98712695e-01, 6.20991349e-01, 4.35687043e-02, 6.84041083e-01,\n        1.96084052e-01, 2.73407809e-02],\n       [5.50953269e-01, 8.13313663e-01, 8.59941125e-01, 1.03520922e-01,\n        6.63042784e-01, 7.10075200e-01, 2.94516981e-01, 9.71364021e-01,\n        2.78687477e-01, 6.99821860e-02],\n       [5.19280374e-01, 6.94314897e-01, 2.44659781e-01, 3.38582188e-01,\n        5.63627958e-01, 8.86678159e-01, 7.47325897e-01, 2.09591955e-01,\n        2.51777083e-01, 5.23880661e-01],\n       [7.68958688e-01, 6.18761778e-01, 5.01324296e-01, 5.97125351e-01,\n        7.56060004e-01, 5.37079811e-01, 8.97752762e-01, 9.47067499e-01,\n        9.15354490e-01, 7.54518330e-01],\n       [2.46321008e-01, 3.85271460e-01, 2.79999942e-01, 6.57660246e-01,\n        3.24221611e-01, 7.54391611e-01, 1.13509081e-01, 7.75364757e-01,\n        5.85901976e-01, 8.35388660e-01],\n       [4.30875659e-01, 6.24964476e-01, 5.54412127e-01, 9.75671291e-01,\n        7.55474389e-01, 5.44813275e-01, 1.74032092e-01, 9.04114246e-01,\n        2.05837786e-01, 6.50043249e-01],\n       [9.36471879e-01, 2.23579630e-01, 2.25923538e-01, 8.51818919e-01,\n        8.27655017e-01, 3.51703346e-01, 2.65096277e-01, 1.27388477e-01,\n        9.87936080e-01, 8.35343122e-01],\n       [8.99391592e-01, 5.13679326e-01, 1.14384830e-01, 5.25803380e-02,\n        3.30582112e-01, 9.20330405e-01, 9.47581828e-01, 8.41163874e-01,\n        1.58679143e-01, 4.19923156e-01],\n       [2.46242926e-01, 2.05349773e-01, 6.84825838e-01, 4.86111671e-01,\n        3.24909657e-01, 1.00214459e-01, 5.44763386e-01, 3.47025156e-01,\n        3.91095817e-01, 3.10508728e-01],\n       [3.87195200e-01, 5.55859566e-01, 1.41438060e-02, 8.47647011e-01,\n        9.21919882e-01, 5.50529718e-01, 2.68021107e-01, 9.90239024e-01,\n        3.83194029e-01, 6.93655372e-01],\n       [6.89952552e-01, 4.34309065e-01, 1.99158162e-01, 9.66579378e-01,\n        6.36908561e-02, 4.85149384e-01, 2.20730707e-01, 2.93974131e-01,\n        8.28527331e-01, 3.67265552e-01],\n       [8.33482668e-02, 1.96309000e-01, 8.60373437e-01, 9.77028847e-01,\n        2.67982155e-01, 6.75408959e-01, 8.11989978e-02, 7.23465621e-01,\n        4.16436613e-01, 9.18159902e-01],\n       [3.11536163e-01, 9.41466987e-01, 5.03247440e-01, 3.48892927e-01,\n        6.47019625e-01, 2.49746203e-01, 2.29763597e-01, 1.96346447e-01,\n        9.59899545e-01, 4.92913723e-01],\n       [7.51614988e-01, 4.73991871e-01, 5.87540150e-01, 5.84138989e-01,\n        9.79886293e-01, 6.68433130e-01, 2.39769474e-01, 1.51976589e-02,\n        2.18682140e-01, 4.55519646e-01],\n       [3.93420339e-01, 8.12326252e-01, 7.85556734e-01, 8.90959650e-02,\n        9.52010751e-01, 5.27456701e-01, 5.96403956e-01, 4.05056775e-01,\n        6.49500966e-01, 8.71326327e-01],\n       [6.73935950e-01, 9.70098555e-01, 7.01122224e-01, 8.21720719e-01,\n        4.50395830e-02, 6.72698498e-01, 6.54752672e-01, 1.01746053e-01,\n        8.42387497e-01, 6.14172399e-01],\n       [9.83280912e-02, 5.94467103e-01, 4.78415847e-01, 2.33293563e-01,\n        1.97560899e-02, 3.65567267e-01, 6.19851053e-01, 3.29279125e-01,\n        3.07254642e-01, 7.51121223e-01],\n       [7.58624673e-01, 7.18765855e-01, 1.01181954e-01, 5.16165972e-01,\n        5.57798684e-01, 7.44804502e-01, 9.03177738e-01, 3.69038880e-01,\n        4.28663462e-01, 7.32767463e-01],\n       [6.62636399e-01, 5.57869911e-01, 3.50139618e-01, 1.95352346e-01,\n        1.83807373e-01, 8.15832913e-02, 8.12008530e-02, 8.45798194e-01,\n        3.83672744e-01, 6.07396215e-02],\n       [8.96425664e-01, 2.23270476e-01, 2.68124431e-01, 1.94497839e-01,\n        9.67501044e-01, 1.12540089e-01, 7.22163260e-01, 9.32088733e-01,\n        6.68001294e-01, 8.58726621e-01],\n       [2.42447108e-01, 6.73927963e-01, 7.00871348e-01, 4.58332509e-01,\n        8.70545626e-01, 6.94386125e-01, 8.94877791e-01, 7.53204346e-01,\n        5.20290434e-01, 4.98688221e-01],\n       [4.53727633e-01, 2.16468628e-02, 5.35141408e-01, 4.22973245e-01,\n        1.57533601e-01, 1.19069695e-01, 4.49351877e-01, 3.99130546e-02,\n        9.86579895e-01, 3.78120929e-01],\n       [3.82109195e-01, 5.11263013e-02, 4.26672339e-01, 1.57454368e-02,\n        3.00936326e-02, 3.39099228e-01, 8.20968926e-01, 4.58821088e-01,\n        1.48405796e-02, 1.63220033e-01],\n       [7.39922702e-01, 7.38293707e-01, 7.54522920e-01, 3.51669371e-01,\n        3.52276951e-01, 8.02075684e-01, 3.98137897e-01, 7.27191031e-01,\n        5.81122994e-01, 3.64341676e-01],\n       [8.00065175e-02, 1.16125375e-01, 8.89558733e-01, 4.52340513e-01,\n        9.94004548e-01, 3.63896936e-01, 2.49954298e-01, 3.50539327e-01,\n        3.43086094e-01, 6.37356758e-01],\n       [1.27375638e-02, 7.63268650e-01, 4.16414618e-01, 4.32239205e-01,\n        4.81115013e-01, 4.49212462e-01, 4.97470886e-01, 3.45904320e-01,\n        4.53346133e-01, 4.04651344e-01],\n       [5.18242717e-01, 6.23269081e-01, 2.41040602e-01, 5.08437157e-01,\n        5.94621897e-01, 1.69483144e-02, 5.20493746e-01, 2.39293247e-01,\n        4.04538542e-01, 8.26530159e-01],\n       [3.26235592e-01, 4.83216912e-01, 2.47411542e-02, 3.08750868e-01,\n        6.39721096e-01, 3.15161765e-01, 2.05797508e-01, 2.90655673e-01,\n        9.54378307e-01, 8.68018195e-02],\n       [4.63357776e-01, 5.83869033e-02, 5.38658261e-01, 1.46035731e-01,\n        6.34084821e-01, 2.64397472e-01, 6.90915406e-01, 3.47146064e-01,\n        4.16848855e-03, 2.94894695e-01]])","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# Instantiate input with 100x10 tensors i.e 10 features\nborrower_features = tf.Variable([[6.96469188e-01, 2.86139339e-01, 2.26851448e-01, 5.51314771e-01,\n        7.19468951e-01, 4.23106462e-01, 9.80764210e-01, 6.84829712e-01,\n        4.80931908e-01, 3.92117530e-01],\n       [3.43178004e-01, 7.29049683e-01, 4.38572258e-01, 5.96778952e-02,\n        3.98044258e-01, 7.37995386e-01, 1.82491735e-01, 1.75451756e-01,\n        5.31551361e-01, 5.31827569e-01],\n       [6.34400964e-01, 8.49431813e-01, 7.24455297e-01, 6.11023486e-01,\n        7.22443402e-01, 3.22958916e-01, 3.61788660e-01, 2.28263229e-01,\n        2.93714046e-01, 6.30976140e-01],\n       [9.21049416e-02, 4.33701187e-01, 4.30862755e-01, 4.93685097e-01,\n        4.25830305e-01, 3.12261224e-01, 4.26351309e-01, 8.93389165e-01,\n        9.44160044e-01, 5.01836658e-01],\n       [6.23952925e-01, 1.15618393e-01, 3.17285478e-01, 4.14826214e-01,\n        8.66309166e-01, 2.50455379e-01, 4.83034253e-01, 9.85559762e-01,\n        5.19485116e-01, 6.12894535e-01],\n       [1.20628662e-01, 8.26340795e-01, 6.03060126e-01, 5.45068026e-01,\n        3.42763841e-01, 3.04120779e-01, 4.17022198e-01, 6.81300759e-01,\n        8.75456870e-01, 5.10422349e-01],\n       [6.69313788e-01, 5.85936546e-01, 6.24903500e-01, 6.74689054e-01,\n        8.42342436e-01, 8.31949860e-02, 7.63682842e-01, 2.43666381e-01,\n        1.94222957e-01, 5.72456956e-01],\n       [9.57125202e-02, 8.85326803e-01, 6.27248943e-01, 7.23416328e-01,\n        1.61292069e-02, 5.94431877e-01, 5.56785166e-01, 1.58959642e-01,\n        1.53070509e-01, 6.95529521e-01],\n       [3.18766415e-01, 6.91970289e-01, 5.54383278e-01, 3.88950586e-01,\n        9.25132513e-01, 8.41669977e-01, 3.57397556e-01, 4.35914621e-02,\n        3.04768085e-01, 3.98185670e-01],\n       [7.04958856e-01, 9.95358467e-01, 3.55914861e-01, 7.62547791e-01,\n        5.93176901e-01, 6.91701770e-01, 1.51127458e-01, 3.98876280e-01,\n        2.40855902e-01, 3.43456000e-01],\n       [5.13128161e-01, 6.66624546e-01, 1.05908483e-01, 1.30894944e-01,\n        3.21980596e-01, 6.61564350e-01, 8.46506238e-01, 5.53257346e-01,\n        8.54452491e-01, 3.84837806e-01],\n       [3.16787899e-01, 3.54264677e-01, 1.71081826e-01, 8.29112649e-01,\n        3.38670850e-01, 5.52370071e-01, 5.78551471e-01, 5.21533072e-01,\n        2.68806447e-03, 9.88345444e-01],\n       [9.05341566e-01, 2.07635865e-01, 2.92489409e-01, 5.20010173e-01,\n        9.01911378e-01, 9.83630896e-01, 2.57542074e-01, 5.64359069e-01,\n        8.06968689e-01, 3.94370049e-01],\n       [7.31073022e-01, 1.61069021e-01, 6.00698590e-01, 8.65864456e-01,\n        9.83521581e-01, 7.93657899e-02, 4.28347290e-01, 2.04542860e-01,\n        4.50636476e-01, 5.47763586e-01],\n       [9.33267102e-02, 2.96860784e-01, 9.27584231e-01, 5.69003761e-01,\n        4.57412004e-01, 7.53525972e-01, 7.41862178e-01, 4.85790335e-02,\n        7.08697379e-01, 8.39243352e-01],\n       [1.65937886e-01, 7.80997932e-01, 2.86536604e-01, 3.06469738e-01,\n        6.65261447e-01, 1.11392170e-01, 6.64872468e-01, 8.87856781e-01,\n        6.96311295e-01, 4.40327883e-01],\n       [4.38214391e-01, 7.65096068e-01, 5.65641999e-01, 8.49041641e-02,\n        5.82671106e-01, 8.14843714e-01, 3.37066382e-01, 9.27576602e-01,\n        7.50716984e-01, 5.74063838e-01],\n       [7.51644015e-01, 7.91489631e-02, 8.59389067e-01, 8.21504116e-01,\n        9.09871638e-01, 1.28631204e-01, 8.17800835e-02, 1.38415575e-01,\n        3.99378717e-01, 4.24306870e-01],\n       [5.62218368e-01, 1.22243546e-01, 2.01399505e-01, 8.11644375e-01,\n        4.67987567e-01, 8.07938218e-01, 7.42637832e-03, 5.51592708e-01,\n        9.31932151e-01, 5.82175434e-01],\n       [2.06095725e-01, 7.17757583e-01, 3.78985852e-01, 6.68383956e-01,\n        2.93197222e-02, 6.35900378e-01, 3.21979336e-02, 7.44780660e-01,\n        4.72912997e-01, 1.21754356e-01],\n       [5.42635918e-01, 6.67744428e-02, 6.53364897e-01, 9.96086299e-01,\n        7.69397318e-01, 5.73774099e-01, 1.02635257e-01, 6.99834049e-01,\n        6.61167860e-01, 4.90971319e-02],\n       [7.92299330e-01, 5.18716574e-01, 4.25867707e-01, 7.88187146e-01,\n        4.11569238e-01, 4.81026262e-01, 1.81628838e-01, 3.21318895e-01,\n        8.45533013e-01, 1.86903745e-01],\n       [4.17291075e-01, 9.89034534e-01, 2.36599818e-01, 9.16832328e-01,\n        9.18397486e-01, 9.12963450e-02, 4.63652730e-01, 5.02216339e-01,\n        3.13668936e-01, 4.73395362e-02],\n       [2.41685644e-01, 9.55296382e-02, 2.38249913e-01, 8.07791114e-01,\n        8.94978285e-01, 4.32228930e-02, 3.01946849e-01, 9.80582178e-01,\n        5.39504826e-01, 6.26309335e-01],\n       [5.54540846e-03, 4.84909445e-01, 9.88328516e-01, 3.75185519e-01,\n        9.70381573e-02, 4.61908758e-01, 9.63004470e-01, 3.41830611e-01,\n        7.98922718e-01, 7.98846304e-01],\n       [2.08248302e-01, 4.43367690e-01, 7.15601265e-01, 4.10519779e-01,\n        1.91006958e-01, 9.67494309e-01, 6.50750339e-01, 8.65459859e-01,\n        2.52423584e-02, 2.66905814e-01],\n       [5.02071083e-01, 6.74486384e-02, 9.93033290e-01, 2.36462399e-01,\n        3.74292195e-01, 2.14011908e-01, 1.05445869e-01, 2.32479781e-01,\n        3.00610125e-01, 6.34442270e-01],\n       [2.81234771e-01, 3.62276763e-01, 5.94284385e-03, 3.65719140e-01,\n        5.33885956e-01, 1.62015840e-01, 5.97433090e-01, 2.93152481e-01,\n        6.32050514e-01, 2.61966046e-02],\n       [8.87593448e-01, 1.61186308e-02, 1.26958027e-01, 7.77162433e-01,\n        4.58952338e-02, 7.10998714e-01, 9.71046150e-01, 8.71682942e-01,\n        7.10161626e-01, 9.58509743e-01],\n       [4.29813325e-01, 8.72878909e-01, 3.55957657e-01, 9.29763675e-01,\n        1.48777649e-01, 9.40029025e-01, 8.32716227e-01, 8.46054852e-01,\n        1.23923011e-01, 5.96486926e-01],\n       [1.63924806e-02, 7.21184373e-01, 7.73751410e-03, 8.48222747e-02,\n        2.25498408e-01, 8.75124514e-01, 3.63576323e-01, 5.39959908e-01,\n        5.68103194e-01, 2.25463361e-01],\n       [5.72146773e-01, 6.60951793e-01, 2.98245400e-01, 4.18626845e-01,\n        4.53088939e-01, 9.32350636e-01, 5.87493777e-01, 9.48252380e-01,\n        5.56034744e-01, 5.00561416e-01],\n       [3.53221106e-03, 4.80889052e-01, 9.27455008e-01, 1.98365688e-01,\n        5.20911328e-02, 4.06778902e-01, 3.72396469e-01, 8.57153058e-01,\n        2.66111158e-02, 9.20149207e-01],\n       [6.80903018e-01, 9.04226005e-01, 6.07529044e-01, 8.11953306e-01,\n        3.35543871e-01, 3.49566221e-01, 3.89874220e-01, 7.54797101e-01,\n        3.69291186e-01, 2.42219806e-01],\n       [9.37668383e-01, 9.08011079e-01, 3.48797321e-01, 6.34638071e-01,\n        2.73842216e-01, 2.06115127e-01, 3.36339533e-01, 3.27099890e-01,\n        8.82276118e-01, 8.22303832e-01],\n       [7.09623218e-01, 9.59345222e-01, 4.22543347e-01, 2.45033041e-01,\n        1.17398441e-01, 3.01053345e-01, 1.45263731e-01, 9.21861008e-02,\n        6.02932215e-01, 3.64187449e-01],\n       [5.64570367e-01, 1.91335723e-01, 6.76905870e-01, 2.15505451e-01,\n        2.78023601e-01, 7.41760433e-01, 5.59737921e-01, 3.34836423e-01,\n        5.42988777e-01, 6.93984687e-01],\n       [9.12132144e-01, 5.80713212e-01, 2.32686386e-01, 7.46697605e-01,\n        7.77769029e-01, 2.00401321e-01, 8.20574224e-01, 4.64934856e-01,\n        7.79766679e-01, 2.37478226e-01],\n       [3.32580268e-01, 9.53697145e-01, 6.57815099e-01, 7.72877812e-01,\n        6.88374341e-01, 2.04304114e-01, 4.70688760e-01, 8.08963895e-01,\n        6.75035119e-01, 6.02788571e-03],\n       [8.74077454e-02, 3.46794724e-01, 9.44365561e-01, 4.91190493e-01,\n        2.70176262e-01, 3.60423714e-01, 2.10652635e-01, 4.21200067e-01,\n        2.18035445e-01, 8.45752478e-01],\n       [4.56270605e-01, 2.79802024e-01, 9.32891667e-01, 3.14351350e-01,\n        9.09714639e-01, 4.34180908e-02, 7.07115054e-01, 4.83889043e-01,\n        4.44221050e-01, 3.63233462e-02],\n       [4.06831913e-02, 3.32753628e-01, 9.47119534e-01, 6.17659986e-01,\n        3.68874848e-01, 6.11977041e-01, 2.06131533e-01, 1.65066436e-01,\n        3.61817271e-01, 8.63353372e-01],\n       [5.09401739e-01, 2.96901524e-01, 9.50251639e-01, 8.15966070e-01,\n        3.22973937e-01, 9.72098231e-01, 9.87351120e-01, 4.08660144e-01,\n        6.55923128e-01, 4.05653208e-01],\n       [2.57348120e-01, 8.26526731e-02, 2.63610333e-01, 2.71479845e-01,\n        3.98639083e-01, 1.84886038e-01, 9.53818381e-01, 1.02879882e-01,\n        6.25208557e-01, 4.41697389e-01],\n       [4.23518062e-01, 3.71991783e-01, 8.68314683e-01, 2.80476987e-01,\n        2.05761567e-02, 9.18097019e-01, 8.64480257e-01, 2.76901782e-01,\n        5.23487568e-01, 1.09088197e-01],\n       [9.34270695e-02, 8.37466121e-01, 4.10265714e-01, 6.61716521e-01,\n        9.43200588e-01, 2.45130599e-01, 1.31598311e-02, 2.41484065e-02,\n        7.09385693e-01, 9.24551904e-01],\n       [4.67330277e-01, 3.75109136e-01, 5.42860448e-01, 8.58916819e-01,\n        6.52153850e-01, 2.32979894e-01, 7.74580181e-01, 1.34613499e-01,\n        1.65559977e-01, 6.12682283e-01],\n       [2.38783404e-01, 7.04778552e-01, 3.49518538e-01, 2.77423948e-01,\n        9.98918414e-01, 4.06161249e-02, 6.45822525e-01, 3.86995859e-02,\n        7.60210276e-01, 2.30089962e-01],\n       [8.98318663e-02, 6.48449719e-01, 7.32601225e-01, 6.78095341e-01,\n        5.19009456e-02, 2.94306934e-01, 4.51088339e-01, 2.87103295e-01,\n        8.10513437e-01, 1.31115109e-01],\n       [6.12179339e-01, 9.88214970e-01, 9.02556539e-01, 2.22157061e-01,\n        8.18876142e-05, 9.80597317e-01, 8.82712960e-01, 9.19472456e-01,\n        4.15503561e-01, 7.44615436e-01],\n       [2.12831497e-01, 3.92304063e-01, 8.51548076e-01, 1.27612218e-01,\n        8.93865347e-01, 4.96507972e-01, 4.26095665e-01, 3.05646390e-01,\n        9.16848779e-01, 5.17623484e-01],\n       [8.04026365e-01, 8.57651770e-01, 9.22382355e-01, 3.03380728e-01,\n        3.39810848e-01, 5.95073879e-01, 4.41324145e-01, 9.32842553e-01,\n        3.97564054e-01, 4.77778047e-01],\n       [6.17186069e-01, 4.04739499e-01, 9.92478430e-01, 9.88512859e-02,\n        2.20603317e-01, 3.22655141e-01, 1.47722840e-01, 2.84219235e-01,\n        7.79245317e-01, 5.22891998e-01],\n       [3.39536369e-02, 9.82622564e-01, 6.16006494e-01, 5.89394793e-02,\n        6.61168754e-01, 3.78369361e-01, 1.35673299e-01, 5.63664615e-01,\n        7.27079928e-01, 6.71126604e-01],\n       [2.47513160e-01, 5.24866223e-01, 5.37663460e-01, 7.16803372e-01,\n        3.59867334e-01, 7.97732592e-01, 6.27921820e-01, 3.83316055e-02,\n        5.46479046e-01, 8.61912072e-01],\n       [5.67574143e-01, 1.75828263e-01, 5.10376394e-01, 7.56945848e-01,\n        1.10105194e-01, 8.17099094e-01, 1.67481646e-01, 5.34076512e-01,\n        3.85743469e-01, 2.48623773e-01],\n       [6.47432506e-01, 3.73921096e-02, 7.60045826e-01, 5.26940644e-01,\n        8.75771224e-01, 5.20718336e-01, 3.50331701e-02, 1.43600971e-01,\n        7.95604587e-01, 4.91976053e-01],\n       [4.41879272e-01, 3.18434775e-01, 2.84549206e-01, 9.65886295e-01,\n        4.32969332e-01, 8.84003043e-01, 6.48163140e-01, 8.58427644e-01,\n        8.52449536e-01, 9.56312001e-01],\n       [6.97942257e-01, 8.05396914e-01, 7.33127892e-01, 6.05226815e-01,\n        7.17354119e-01, 7.15750396e-01, 4.09077927e-02, 5.16110837e-01,\n        7.92651355e-01, 2.42962182e-01],\n       [4.65147972e-01, 4.34985697e-01, 4.02787179e-01, 1.21839531e-01,\n        5.25711536e-01, 4.46248353e-01, 6.63392782e-01, 5.49413085e-01,\n        2.75429301e-02, 3.19179893e-02],\n       [7.01359808e-01, 7.07581103e-01, 9.59939122e-01, 8.76704693e-01,\n        4.68059659e-01, 6.25906527e-01, 4.57181722e-01, 2.22946241e-01,\n        3.76677006e-01, 1.03884235e-01],\n       [6.66527092e-01, 1.92030147e-01, 4.75467801e-01, 9.67436612e-01,\n        3.16689312e-02, 1.51729956e-01, 2.98579186e-01, 9.41806972e-01,\n        9.08841789e-01, 1.62000835e-01],\n       [9.81117785e-01, 7.50747502e-01, 5.39977074e-01, 9.31702912e-01,\n        8.80607128e-01, 3.91316503e-01, 6.56343222e-01, 6.47385120e-01,\n        3.26968193e-01, 1.79390177e-01],\n       [4.66809869e-01, 2.63281047e-01, 3.55065137e-01, 9.54143941e-01,\n        4.61137861e-01, 6.84891462e-01, 3.36229891e-01, 9.95861053e-01,\n        6.58767581e-01, 1.96009472e-01],\n       [9.81839970e-02, 9.43180561e-01, 9.44777846e-01, 6.21328354e-01,\n        1.69914998e-02, 2.25534886e-01, 8.01276803e-01, 8.75459850e-01,\n        4.53989804e-01, 3.65520626e-01],\n       [2.74224997e-01, 1.16970517e-01, 1.15744539e-01, 9.52602684e-01,\n        8.08626115e-01, 1.64779365e-01, 2.07050055e-01, 6.55551553e-01,\n        7.64664233e-01, 8.10314834e-01],\n       [1.63337693e-01, 9.84128296e-01, 2.27802068e-01, 5.89415431e-01,\n        5.87615728e-01, 9.67361867e-01, 6.57667458e-01, 5.84904253e-01,\n        5.18772602e-01, 7.64657557e-01],\n       [1.06055260e-01, 2.09190114e-03, 9.52488840e-01, 4.98657674e-01,\n        3.28335375e-01, 3.68053257e-01, 8.03843319e-01, 3.82370204e-01,\n        7.70169199e-01, 4.40461993e-01],\n       [8.44077468e-01, 7.62040615e-02, 4.81128335e-01, 4.66849715e-01,\n        2.64327973e-01, 9.43614721e-01, 9.05028462e-01, 4.43596303e-01,\n        9.71596092e-02, 2.06783146e-01],\n       [2.71491826e-01, 4.84219760e-01, 3.38377118e-01, 7.74136066e-01,\n        4.76026595e-01, 8.70370507e-01, 9.95781779e-01, 2.19835952e-01,\n        6.11671388e-01, 8.47502291e-01],\n       [9.45236623e-01, 2.90086418e-01, 7.27042735e-01, 1.50161488e-02,\n        8.79142463e-01, 6.39385507e-02, 7.33395398e-01, 9.94610369e-01,\n        5.01189768e-01, 2.09333986e-01],\n       [5.94643593e-01, 6.24149978e-01, 6.68072760e-01, 1.72611743e-01,\n        8.98712695e-01, 6.20991349e-01, 4.35687043e-02, 6.84041083e-01,\n        1.96084052e-01, 2.73407809e-02],\n       [5.50953269e-01, 8.13313663e-01, 8.59941125e-01, 1.03520922e-01,\n        6.63042784e-01, 7.10075200e-01, 2.94516981e-01, 9.71364021e-01,\n        2.78687477e-01, 6.99821860e-02],\n       [5.19280374e-01, 6.94314897e-01, 2.44659781e-01, 3.38582188e-01,\n        5.63627958e-01, 8.86678159e-01, 7.47325897e-01, 2.09591955e-01,\n        2.51777083e-01, 5.23880661e-01],\n       [7.68958688e-01, 6.18761778e-01, 5.01324296e-01, 5.97125351e-01,\n        7.56060004e-01, 5.37079811e-01, 8.97752762e-01, 9.47067499e-01,\n        9.15354490e-01, 7.54518330e-01],\n       [2.46321008e-01, 3.85271460e-01, 2.79999942e-01, 6.57660246e-01,\n        3.24221611e-01, 7.54391611e-01, 1.13509081e-01, 7.75364757e-01,\n        5.85901976e-01, 8.35388660e-01],\n       [4.30875659e-01, 6.24964476e-01, 5.54412127e-01, 9.75671291e-01,\n        7.55474389e-01, 5.44813275e-01, 1.74032092e-01, 9.04114246e-01,\n        2.05837786e-01, 6.50043249e-01],\n       [9.36471879e-01, 2.23579630e-01, 2.25923538e-01, 8.51818919e-01,\n        8.27655017e-01, 3.51703346e-01, 2.65096277e-01, 1.27388477e-01,\n        9.87936080e-01, 8.35343122e-01],\n       [8.99391592e-01, 5.13679326e-01, 1.14384830e-01, 5.25803380e-02,\n        3.30582112e-01, 9.20330405e-01, 9.47581828e-01, 8.41163874e-01,\n        1.58679143e-01, 4.19923156e-01],\n       [2.46242926e-01, 2.05349773e-01, 6.84825838e-01, 4.86111671e-01,\n        3.24909657e-01, 1.00214459e-01, 5.44763386e-01, 3.47025156e-01,\n        3.91095817e-01, 3.10508728e-01],\n       [3.87195200e-01, 5.55859566e-01, 1.41438060e-02, 8.47647011e-01,\n        9.21919882e-01, 5.50529718e-01, 2.68021107e-01, 9.90239024e-01,\n        3.83194029e-01, 6.93655372e-01],\n       [6.89952552e-01, 4.34309065e-01, 1.99158162e-01, 9.66579378e-01,\n        6.36908561e-02, 4.85149384e-01, 2.20730707e-01, 2.93974131e-01,\n        8.28527331e-01, 3.67265552e-01],\n       [8.33482668e-02, 1.96309000e-01, 8.60373437e-01, 9.77028847e-01,\n        2.67982155e-01, 6.75408959e-01, 8.11989978e-02, 7.23465621e-01,\n        4.16436613e-01, 9.18159902e-01],\n       [3.11536163e-01, 9.41466987e-01, 5.03247440e-01, 3.48892927e-01,\n        6.47019625e-01, 2.49746203e-01, 2.29763597e-01, 1.96346447e-01,\n        9.59899545e-01, 4.92913723e-01],\n       [7.51614988e-01, 4.73991871e-01, 5.87540150e-01, 5.84138989e-01,\n        9.79886293e-01, 6.68433130e-01, 2.39769474e-01, 1.51976589e-02,\n        2.18682140e-01, 4.55519646e-01],\n       [3.93420339e-01, 8.12326252e-01, 7.85556734e-01, 8.90959650e-02,\n        9.52010751e-01, 5.27456701e-01, 5.96403956e-01, 4.05056775e-01,\n        6.49500966e-01, 8.71326327e-01],\n       [6.73935950e-01, 9.70098555e-01, 7.01122224e-01, 8.21720719e-01,\n        4.50395830e-02, 6.72698498e-01, 6.54752672e-01, 1.01746053e-01,\n        8.42387497e-01, 6.14172399e-01],\n       [9.83280912e-02, 5.94467103e-01, 4.78415847e-01, 2.33293563e-01,\n        1.97560899e-02, 3.65567267e-01, 6.19851053e-01, 3.29279125e-01,\n        3.07254642e-01, 7.51121223e-01],\n       [7.58624673e-01, 7.18765855e-01, 1.01181954e-01, 5.16165972e-01,\n        5.57798684e-01, 7.44804502e-01, 9.03177738e-01, 3.69038880e-01,\n        4.28663462e-01, 7.32767463e-01],\n       [6.62636399e-01, 5.57869911e-01, 3.50139618e-01, 1.95352346e-01,\n        1.83807373e-01, 8.15832913e-02, 8.12008530e-02, 8.45798194e-01,\n        3.83672744e-01, 6.07396215e-02],\n       [8.96425664e-01, 2.23270476e-01, 2.68124431e-01, 1.94497839e-01,\n        9.67501044e-01, 1.12540089e-01, 7.22163260e-01, 9.32088733e-01,\n        6.68001294e-01, 8.58726621e-01],\n       [2.42447108e-01, 6.73927963e-01, 7.00871348e-01, 4.58332509e-01,\n        8.70545626e-01, 6.94386125e-01, 8.94877791e-01, 7.53204346e-01,\n        5.20290434e-01, 4.98688221e-01],\n       [4.53727633e-01, 2.16468628e-02, 5.35141408e-01, 4.22973245e-01,\n        1.57533601e-01, 1.19069695e-01, 4.49351877e-01, 3.99130546e-02,\n        9.86579895e-01, 3.78120929e-01],\n       [3.82109195e-01, 5.11263013e-02, 4.26672339e-01, 1.57454368e-02,\n        3.00936326e-02, 3.39099228e-01, 8.20968926e-01, 4.58821088e-01,\n        1.48405796e-02, 1.63220033e-01],\n       [7.39922702e-01, 7.38293707e-01, 7.54522920e-01, 3.51669371e-01,\n        3.52276951e-01, 8.02075684e-01, 3.98137897e-01, 7.27191031e-01,\n        5.81122994e-01, 3.64341676e-01],\n       [8.00065175e-02, 1.16125375e-01, 8.89558733e-01, 4.52340513e-01,\n        9.94004548e-01, 3.63896936e-01, 2.49954298e-01, 3.50539327e-01,\n        3.43086094e-01, 6.37356758e-01],\n       [1.27375638e-02, 7.63268650e-01, 4.16414618e-01, 4.32239205e-01,\n        4.81115013e-01, 4.49212462e-01, 4.97470886e-01, 3.45904320e-01,\n        4.53346133e-01, 4.04651344e-01],\n       [5.18242717e-01, 6.23269081e-01, 2.41040602e-01, 5.08437157e-01,\n        5.94621897e-01, 1.69483144e-02, 5.20493746e-01, 2.39293247e-01,\n        4.04538542e-01, 8.26530159e-01],\n       [3.26235592e-01, 4.83216912e-01, 2.47411542e-02, 3.08750868e-01,\n        6.39721096e-01, 3.15161765e-01, 2.05797508e-01, 2.90655673e-01,\n        9.54378307e-01, 8.68018195e-02],\n       [4.63357776e-01, 5.83869033e-02, 5.38658261e-01, 1.46035731e-01,\n        6.34084821e-01, 2.64397472e-01, 6.90915406e-01, 3.47146064e-01,\n        4.16848855e-03, 2.94894695e-01]])"},"cell_type":"code","id":"fcdbd5c6-e3a2-4b1c-8a7b-41ee8da9ca5b","execution_count":9,"outputs":[]},{"source":"# Define the first dense layer\ndense1 = tf.keras.layers.Dense(7, activation='sigmoid')(borrower_features)\n\n# Define a dense layer with 3 output nodes\ndense2 = tf.keras.layers.Dense(3, activation='sigmoid')(dense1)\n\n# Define a dense layer with 1 output node\npredictions = tf.keras.layers.Dense(1,activation='sigmoid')(dense2)\n\n# Print the shapes of dense1, dense2, and predictions\nprint('\\n shape of dense1: ', dense1.shape)\nprint('\\n shape of dense2: ', dense2.shape)\nprint('\\n shape of predictions: ', predictions.shape)","metadata":{"executionTime":95,"lastSuccessfullyExecutedCode":"# Define the first dense layer\ndense1 = tf.keras.layers.Dense(7, activation='sigmoid')(borrower_features)\n\n# Define a dense layer with 3 output nodes\ndense2 = tf.keras.layers.Dense(3, activation='sigmoid')(dense1)\n\n# Define a dense layer with 1 output node\npredictions = tf.keras.layers.Dense(1,activation='sigmoid')(dense2)\n\n# Print the shapes of dense1, dense2, and predictions\nprint('\\n shape of dense1: ', dense1.shape)\nprint('\\n shape of dense2: ', dense2.shape)\nprint('\\n shape of predictions: ', predictions.shape)"},"cell_type":"code","id":"b0c52ae7-c9c0-4bb4-a397-66477b53e8a9","execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":"\n shape of dense1:  (100, 7)\n\n shape of dense2:  (100, 3)\n\n shape of predictions:  (100, 1)\n"}]},{"source":"# Prediction for each of 100 records \npredictions","metadata":{"executionTime":92,"lastSuccessfullyExecutedCode":"# Prediction for each of 100 records \npredictions"},"cell_type":"code","id":"40c445ef-2ca7-4c95-8c60-8b1baf29a4e9","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"<tf.Tensor: shape=(100, 1), dtype=float32, numpy=\narray([[0.4985526 ],\n       [0.49875703],\n       [0.49849975],\n       [0.49983874],\n       [0.49983993],\n       [0.49934837],\n       [0.49830785],\n       [0.49932876],\n       [0.49789917],\n       [0.49861127],\n       [0.49831784],\n       [0.5007524 ],\n       [0.4986023 ],\n       [0.49870038],\n       [0.49858513],\n       [0.49938768],\n       [0.49905568],\n       [0.4988418 ],\n       [0.4999703 ],\n       [0.49977127],\n       [0.4989247 ],\n       [0.4984274 ],\n       [0.49841017],\n       [0.50053674],\n       [0.49885312],\n       [0.4991906 ],\n       [0.49961472],\n       [0.4984847 ],\n       [0.5004008 ],\n       [0.4995108 ],\n       [0.49911913],\n       [0.49911925],\n       [0.5009324 ],\n       [0.4988984 ],\n       [0.49915692],\n       [0.49850342],\n       [0.4990199 ],\n       [0.49778605],\n       [0.49844795],\n       [0.50025076],\n       [0.4977723 ],\n       [0.49976042],\n       [0.49782026],\n       [0.49858165],\n       [0.49756512],\n       [0.49931368],\n       [0.49872458],\n       [0.49763608],\n       [0.49855995],\n       [0.4988284 ],\n       [0.49822816],\n       [0.49881753],\n       [0.49888355],\n       [0.49928662],\n       [0.49892396],\n       [0.49954382],\n       [0.49887276],\n       [0.5000921 ],\n       [0.49820134],\n       [0.49835643],\n       [0.4975395 ],\n       [0.49991783],\n       [0.49783632],\n       [0.49954477],\n       [0.49931452],\n       [0.500528  ],\n       [0.4990416 ],\n       [0.49871153],\n       [0.49823615],\n       [0.49867263],\n       [0.49828213],\n       [0.49833816],\n       [0.4983137 ],\n       [0.49814573],\n       [0.4987162 ],\n       [0.5007382 ],\n       [0.4999715 ],\n       [0.49913648],\n       [0.49873632],\n       [0.4990851 ],\n       [0.50024396],\n       [0.49934065],\n       [0.5009087 ],\n       [0.49839815],\n       [0.49814865],\n       [0.4983273 ],\n       [0.49802378],\n       [0.49978957],\n       [0.49850017],\n       [0.4996579 ],\n       [0.49952555],\n       [0.49831033],\n       [0.49882126],\n       [0.49911794],\n       [0.4984697 ],\n       [0.49923092],\n       [0.4988886 ],\n       [0.49945065],\n       [0.49849334],\n       [0.49869156]], dtype=float32)>"},"metadata":{}}]},{"source":"# Activation Functions\n\n1. Sigmoid activation function \n- Primarily in the output layer of Binary classification problems\n- Low level: `tf.keras.activations.sigmoid()`\n- High-level:`sigmoid` \n\n**Sigmoid Activation function** is very simple which takes a real value as input and gives probability that âs always between 0 or 1. It looks like âSâ shape.\n\n![image-9](image-9.png)\n\n2. Rectified Linear Unit (ReLU) activation function\n- Typically used for Hidden Layers\n- Low level: `tf.keras.activations.relu()`\n- High-level:`relu` \n- The formula is deceptively simple: ððð¥(0,ð§) \n![image-12](image-12.png)\n\n![image-10](image-10.png)\n\n3. Softmax activation function\n- Output layer (>2 classes)\n- Low level: `tf.keras.activations.softmax()`\n- High-level:`softmax`\n","metadata":{},"cell_type":"markdown","id":"89a2e73f-67b2-49e5-aa7d-3be1b74222be"},{"source":"## Binary Classification Problems","metadata":{},"cell_type":"markdown","id":"0d2d2e9a-658b-453b-acda-0187552a98ce"},{"source":"import pandas as pd\ncredit_card = pd.read_csv('datasets/uci_credit_card.csv')\ncredit_card.head()","metadata":{"executionTime":214,"lastSuccessfullyExecutedCode":"import pandas as pd\ncredit_card = pd.read_csv('datasets/uci_credit_card.csv')\ncredit_card.head()"},"cell_type":"code","id":"82842035-5b36-4199-8852-6f8c135ee884","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"application/com.datacamp.data-table.v1+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"ID","type":"integer"},{"name":"LIMIT_BAL","type":"number"},{"name":"SEX","type":"integer"},{"name":"EDUCATION","type":"integer"},{"name":"MARRIAGE","type":"integer"},{"name":"AGE","type":"integer"},{"name":"PAY_0","type":"integer"},{"name":"PAY_2","type":"integer"},{"name":"PAY_3","type":"integer"},{"name":"PAY_4","type":"integer"},{"name":"PAY_5","type":"integer"},{"name":"PAY_6","type":"integer"},{"name":"BILL_AMT1","type":"number"},{"name":"BILL_AMT2","type":"number"},{"name":"BILL_AMT3","type":"number"},{"name":"BILL_AMT4","type":"number"},{"name":"BILL_AMT5","type":"number"},{"name":"BILL_AMT6","type":"number"},{"name":"PAY_AMT1","type":"number"},{"name":"PAY_AMT2","type":"number"},{"name":"PAY_AMT3","type":"number"},{"name":"PAY_AMT4","type":"number"},{"name":"PAY_AMT5","type":"number"},{"name":"PAY_AMT6","type":"number"},{"name":"default.payment.next.month","type":"integer"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":[{"index":0,"ID":1,"LIMIT_BAL":20000,"SEX":2,"EDUCATION":2,"MARRIAGE":1,"AGE":24,"PAY_0":2,"PAY_2":2,"PAY_3":-1,"PAY_4":-1,"PAY_5":-2,"PAY_6":-2,"BILL_AMT1":3913,"BILL_AMT2":3102,"BILL_AMT3":689,"BILL_AMT4":0,"BILL_AMT5":0,"BILL_AMT6":0,"PAY_AMT1":0,"PAY_AMT2":689,"PAY_AMT3":0,"PAY_AMT4":0,"PAY_AMT5":0,"PAY_AMT6":0,"default.payment.next.month":1},{"index":1,"ID":2,"LIMIT_BAL":120000,"SEX":2,"EDUCATION":2,"MARRIAGE":2,"AGE":26,"PAY_0":-1,"PAY_2":2,"PAY_3":0,"PAY_4":0,"PAY_5":0,"PAY_6":2,"BILL_AMT1":2682,"BILL_AMT2":1725,"BILL_AMT3":2682,"BILL_AMT4":3272,"BILL_AMT5":3455,"BILL_AMT6":3261,"PAY_AMT1":0,"PAY_AMT2":1000,"PAY_AMT3":1000,"PAY_AMT4":1000,"PAY_AMT5":0,"PAY_AMT6":2000,"default.payment.next.month":1},{"index":2,"ID":3,"LIMIT_BAL":90000,"SEX":2,"EDUCATION":2,"MARRIAGE":2,"AGE":34,"PAY_0":0,"PAY_2":0,"PAY_3":0,"PAY_4":0,"PAY_5":0,"PAY_6":0,"BILL_AMT1":29239,"BILL_AMT2":14027,"BILL_AMT3":13559,"BILL_AMT4":14331,"BILL_AMT5":14948,"BILL_AMT6":15549,"PAY_AMT1":1518,"PAY_AMT2":1500,"PAY_AMT3":1000,"PAY_AMT4":1000,"PAY_AMT5":1000,"PAY_AMT6":5000,"default.payment.next.month":0},{"index":3,"ID":4,"LIMIT_BAL":50000,"SEX":2,"EDUCATION":2,"MARRIAGE":1,"AGE":37,"PAY_0":0,"PAY_2":0,"PAY_3":0,"PAY_4":0,"PAY_5":0,"PAY_6":0,"BILL_AMT1":46990,"BILL_AMT2":48233,"BILL_AMT3":49291,"BILL_AMT4":28314,"BILL_AMT5":28959,"BILL_AMT6":29547,"PAY_AMT1":2000,"PAY_AMT2":2019,"PAY_AMT3":1200,"PAY_AMT4":1100,"PAY_AMT5":1069,"PAY_AMT6":1000,"default.payment.next.month":0},{"index":4,"ID":5,"LIMIT_BAL":50000,"SEX":1,"EDUCATION":2,"MARRIAGE":1,"AGE":57,"PAY_0":-1,"PAY_2":0,"PAY_3":-1,"PAY_4":0,"PAY_5":0,"PAY_6":0,"BILL_AMT1":8617,"BILL_AMT2":5670,"BILL_AMT3":35835,"BILL_AMT4":20940,"BILL_AMT5":19146,"BILL_AMT6":19131,"PAY_AMT1":2000,"PAY_AMT2":36681,"PAY_AMT3":10000,"PAY_AMT4":9000,"PAY_AMT5":689,"PAY_AMT6":679,"default.payment.next.month":0}]},"total_rows":5,"truncation_type":null},"text/plain":"   ID  LIMIT_BAL  SEX  ...  PAY_AMT5  PAY_AMT6  default.payment.next.month\n0   1    20000.0    2  ...       0.0       0.0                           1\n1   2   120000.0    2  ...       0.0    2000.0                           1\n2   3    90000.0    2  ...    1000.0    5000.0                           0\n3   4    50000.0    2  ...    1069.0    1000.0                           0\n4   5    50000.0    1  ...     689.0     679.0                           0\n\n[5 rows x 25 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>LIMIT_BAL</th>\n      <th>SEX</th>\n      <th>EDUCATION</th>\n      <th>MARRIAGE</th>\n      <th>AGE</th>\n      <th>PAY_0</th>\n      <th>PAY_2</th>\n      <th>PAY_3</th>\n      <th>PAY_4</th>\n      <th>PAY_5</th>\n      <th>PAY_6</th>\n      <th>BILL_AMT1</th>\n      <th>BILL_AMT2</th>\n      <th>BILL_AMT3</th>\n      <th>BILL_AMT4</th>\n      <th>BILL_AMT5</th>\n      <th>BILL_AMT6</th>\n      <th>PAY_AMT1</th>\n      <th>PAY_AMT2</th>\n      <th>PAY_AMT3</th>\n      <th>PAY_AMT4</th>\n      <th>PAY_AMT5</th>\n      <th>PAY_AMT6</th>\n      <th>default.payment.next.month</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>20000.0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>24</td>\n      <td>2</td>\n      <td>2</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-2</td>\n      <td>-2</td>\n      <td>3913.0</td>\n      <td>3102.0</td>\n      <td>689.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>689.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>120000.0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>26</td>\n      <td>-1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2682.0</td>\n      <td>1725.0</td>\n      <td>2682.0</td>\n      <td>3272.0</td>\n      <td>3455.0</td>\n      <td>3261.0</td>\n      <td>0.0</td>\n      <td>1000.0</td>\n      <td>1000.0</td>\n      <td>1000.0</td>\n      <td>0.0</td>\n      <td>2000.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>90000.0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>34</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>29239.0</td>\n      <td>14027.0</td>\n      <td>13559.0</td>\n      <td>14331.0</td>\n      <td>14948.0</td>\n      <td>15549.0</td>\n      <td>1518.0</td>\n      <td>1500.0</td>\n      <td>1000.0</td>\n      <td>1000.0</td>\n      <td>1000.0</td>\n      <td>5000.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>50000.0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>37</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>46990.0</td>\n      <td>48233.0</td>\n      <td>49291.0</td>\n      <td>28314.0</td>\n      <td>28959.0</td>\n      <td>29547.0</td>\n      <td>2000.0</td>\n      <td>2019.0</td>\n      <td>1200.0</td>\n      <td>1100.0</td>\n      <td>1069.0</td>\n      <td>1000.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>50000.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>57</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8617.0</td>\n      <td>5670.0</td>\n      <td>35835.0</td>\n      <td>20940.0</td>\n      <td>19146.0</td>\n      <td>19131.0</td>\n      <td>2000.0</td>\n      <td>36681.0</td>\n      <td>10000.0</td>\n      <td>9000.0</td>\n      <td>689.0</td>\n      <td>679.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"source":"# Create training data\nbill_amounts = credit_card[['BILL_AMT1','BILL_AMT2','BILL_AMT3']].values\n\n# Actual outputs\ndefault = credit_card[['default.payment.next.month']].values","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# Create training data\nbill_amounts = credit_card[['BILL_AMT1','BILL_AMT2','BILL_AMT3']].values\n\n# Actual outputs\ndefault = credit_card[['default.payment.next.month']].values"},"cell_type":"code","id":"4f0d08ed-7e84-4a8f-b4e7-4fc9ecf31235","execution_count":13,"outputs":[]},{"source":"# Create input layer\ninputs = tf.constant(bill_amounts, tf.float32)\n\n# Create first dense layer with 3 output nodes and input as input layer\ndense1 = tf.keras.layers.Dense(3, activation='relu')(inputs)\n\n# Create second dense layer \ndense2 = tf.keras.layers.Dense(2, activation='relu')(dense1)\n\n# Create output layer\noutputs = tf.keras.layers.Dense(1, activation='sigmoid')(dense2)\n","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# Create input layer\ninputs = tf.constant(bill_amounts, tf.float32)\n\n# Create first dense layer with 3 output nodes and input as input layer\ndense1 = tf.keras.layers.Dense(3, activation='relu')(inputs)\n\n# Create second dense layer \ndense2 = tf.keras.layers.Dense(2, activation='relu')(dense1)\n\n# Create output layer\noutputs = tf.keras.layers.Dense(1, activation='sigmoid')(dense2)\n"},"cell_type":"code","id":"55010261-605b-4861-9893-3fcc382591c2","execution_count":14,"outputs":[]},{"source":"# Calculate error for first 5 records\nerror = default[:5] - outputs[:5] \nerror","metadata":{"executionTime":91,"lastSuccessfullyExecutedCode":"# Calculate error for first 5 records\nerror = default[:5] - outputs[:5] \nerror"},"cell_type":"code","id":"d28f53ad-843d-4c0e-b8ed-c8506e92bfc7","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"<tf.Tensor: shape=(5, 1), dtype=float32, numpy=\narray([[1.],\n       [1.],\n       [0.],\n       [0.],\n       [0.]], dtype=float32)>"},"metadata":{}}]},{"source":"## Multiclass classification problems","metadata":{},"cell_type":"markdown","id":"fec42573-49aa-401c-b635-67c471e7bc3a"},{"source":"# Training data\nborrower_features = credit_card[['BILL_AMT1','BILL_AMT2','BILL_AMT3','BILL_AMT4','BILL_AMT5','BILL_AMT6',\n                                'PAY_AMT1','PAY_AMT2','PAY_AMT3','PAY_AMT4','PAY_AMT5','PAY_AMT6']].values","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# Training data\nborrower_features = credit_card[['BILL_AMT1','BILL_AMT2','BILL_AMT3','BILL_AMT4','BILL_AMT5','BILL_AMT6',\n                                'PAY_AMT1','PAY_AMT2','PAY_AMT3','PAY_AMT4','PAY_AMT5','PAY_AMT6']].values"},"cell_type":"code","id":"09bf78f7-9449-42a6-aede-53d1cbe0672e","execution_count":16,"outputs":[]},{"source":"# Create input layer\ninputs = tf.constant(borrower_features, tf.float32)\n\n# Create dense layer 1\ndense1 = tf.keras.layers.Dense(10, activation='sigmoid')(inputs)\n\n# Create dense layer 2\ndense2 = tf.keras.layers.Dense(8, activation='relu')(dense1)\n\n# Create output layer\noutputs = tf.keras.layers.Dense(6, activation='softmax')(dense2)\n\noutputs.numpy()[:5]","metadata":{"executionTime":102,"lastSuccessfullyExecutedCode":"# Create input layer\ninputs = tf.constant(borrower_features, tf.float32)\n\n# Create dense layer 1\ndense1 = tf.keras.layers.Dense(10, activation='sigmoid')(inputs)\n\n# Create dense layer 2\ndense2 = tf.keras.layers.Dense(8, activation='relu')(dense1)\n\n# Create output layer\noutputs = tf.keras.layers.Dense(6, activation='softmax')(dense2)\n\noutputs.numpy()[:5]"},"cell_type":"code","id":"b8fd8201-004c-4a9b-983b-978d95e58517","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"array([[0.25723812, 0.05895621, 0.25371873, 0.19094351, 0.10025989,\n        0.13888356],\n       [0.22977462, 0.1344639 , 0.18360764, 0.16385192, 0.14626421,\n        0.1420376 ],\n       [0.22977462, 0.1344639 , 0.18360764, 0.16385192, 0.14626421,\n        0.1420376 ],\n       [0.22977462, 0.1344639 , 0.18360764, 0.16385192, 0.14626421,\n        0.1420376 ],\n       [0.20348391, 0.14242448, 0.16659161, 0.18985532, 0.15076187,\n        0.14688276]], dtype=float32)"},"metadata":{}}]},{"source":"**Notice** that each row of outputs sums to one. This is because a row contains the predicted class probabilities for one example. The highest probability is supposed to be the output.","metadata":{},"cell_type":"markdown","id":"e63d28d1-2b0a-4068-b278-be735af38edf"},{"source":"# Optimizers\n\n**1. Stochastic gradient descent (SGD) optimizer**\n- `tf.keras.optimizers.SGD()`\n- `learning_rate` - determines how quickly the model parameters adjust during training\n- Simple and easy to interpret\n\n**2. Root mean squared (RMS) propagation optimizer**\n- Applies different learning rates to each features\n- `tf.keras.optimizers.RMSprop()`\n- `learning_rate`- determines how quickly the model parameters adjust during training\n- `momentum` \n- `decay` - Setting a low value for the decay parameter will prevent momentum from accumulating over long periods during the training process.\n\n**3. Adaptive moment (Adam) optimizer**\n- Similar to RMS prop, you can set the momentum to decay faster by lowering the beta1 parameter.\n- `tf.keras.optimizers.Adam()`\n- `learning_rate`\n- `beta1`","metadata":{},"cell_type":"markdown","id":"7eb8a109-5253-4a0d-acee-1f78a5e975dc"},{"source":"# Training a network in TensorFlow","metadata":{},"cell_type":"markdown","id":"5fcb4aef-f892-464e-ae3d-d531f86f24c0"},{"source":"## Initializing weights / variables in TensorFlow\n- Normal distribution\n- Uniform distribution\n- Glorot initializer","metadata":{},"cell_type":"markdown","id":"c0e6ee13-13f2-4e66-93b7-4489994f5434"},{"source":"## Avoiding overfitting in Neural networks using \"dropout\"\n\n![image-13](image-13.png)\n\nA simple solution to the overfitting problem is to use dropout, an operation that will randomly drop the weights connected to certain nodes in a layer during the training process, as shown on the right. This will force your network to develop more robust rules for classification, since it cannot rely on any particular nodes being passed to an activation function. This will tend to improve out-of-sample performance.","metadata":{},"cell_type":"markdown","id":"7c6ff40f-fdb8-4db4-a2f8-561b938a7cc2"},{"source":"credit_card.head()","metadata":{"executionTime":231,"lastSuccessfullyExecutedCode":"credit_card.head()"},"cell_type":"code","id":"56f1c41d-7fdb-40fb-9aaa-170453057eaa","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"application/com.datacamp.data-table.v1+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"ID","type":"integer"},{"name":"LIMIT_BAL","type":"number"},{"name":"SEX","type":"integer"},{"name":"EDUCATION","type":"integer"},{"name":"MARRIAGE","type":"integer"},{"name":"AGE","type":"integer"},{"name":"PAY_0","type":"integer"},{"name":"PAY_2","type":"integer"},{"name":"PAY_3","type":"integer"},{"name":"PAY_4","type":"integer"},{"name":"PAY_5","type":"integer"},{"name":"PAY_6","type":"integer"},{"name":"BILL_AMT1","type":"number"},{"name":"BILL_AMT2","type":"number"},{"name":"BILL_AMT3","type":"number"},{"name":"BILL_AMT4","type":"number"},{"name":"BILL_AMT5","type":"number"},{"name":"BILL_AMT6","type":"number"},{"name":"PAY_AMT1","type":"number"},{"name":"PAY_AMT2","type":"number"},{"name":"PAY_AMT3","type":"number"},{"name":"PAY_AMT4","type":"number"},{"name":"PAY_AMT5","type":"number"},{"name":"PAY_AMT6","type":"number"},{"name":"default.payment.next.month","type":"integer"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":[{"index":0,"ID":1,"LIMIT_BAL":20000,"SEX":2,"EDUCATION":2,"MARRIAGE":1,"AGE":24,"PAY_0":2,"PAY_2":2,"PAY_3":-1,"PAY_4":-1,"PAY_5":-2,"PAY_6":-2,"BILL_AMT1":3913,"BILL_AMT2":3102,"BILL_AMT3":689,"BILL_AMT4":0,"BILL_AMT5":0,"BILL_AMT6":0,"PAY_AMT1":0,"PAY_AMT2":689,"PAY_AMT3":0,"PAY_AMT4":0,"PAY_AMT5":0,"PAY_AMT6":0,"default.payment.next.month":1},{"index":1,"ID":2,"LIMIT_BAL":120000,"SEX":2,"EDUCATION":2,"MARRIAGE":2,"AGE":26,"PAY_0":-1,"PAY_2":2,"PAY_3":0,"PAY_4":0,"PAY_5":0,"PAY_6":2,"BILL_AMT1":2682,"BILL_AMT2":1725,"BILL_AMT3":2682,"BILL_AMT4":3272,"BILL_AMT5":3455,"BILL_AMT6":3261,"PAY_AMT1":0,"PAY_AMT2":1000,"PAY_AMT3":1000,"PAY_AMT4":1000,"PAY_AMT5":0,"PAY_AMT6":2000,"default.payment.next.month":1},{"index":2,"ID":3,"LIMIT_BAL":90000,"SEX":2,"EDUCATION":2,"MARRIAGE":2,"AGE":34,"PAY_0":0,"PAY_2":0,"PAY_3":0,"PAY_4":0,"PAY_5":0,"PAY_6":0,"BILL_AMT1":29239,"BILL_AMT2":14027,"BILL_AMT3":13559,"BILL_AMT4":14331,"BILL_AMT5":14948,"BILL_AMT6":15549,"PAY_AMT1":1518,"PAY_AMT2":1500,"PAY_AMT3":1000,"PAY_AMT4":1000,"PAY_AMT5":1000,"PAY_AMT6":5000,"default.payment.next.month":0},{"index":3,"ID":4,"LIMIT_BAL":50000,"SEX":2,"EDUCATION":2,"MARRIAGE":1,"AGE":37,"PAY_0":0,"PAY_2":0,"PAY_3":0,"PAY_4":0,"PAY_5":0,"PAY_6":0,"BILL_AMT1":46990,"BILL_AMT2":48233,"BILL_AMT3":49291,"BILL_AMT4":28314,"BILL_AMT5":28959,"BILL_AMT6":29547,"PAY_AMT1":2000,"PAY_AMT2":2019,"PAY_AMT3":1200,"PAY_AMT4":1100,"PAY_AMT5":1069,"PAY_AMT6":1000,"default.payment.next.month":0},{"index":4,"ID":5,"LIMIT_BAL":50000,"SEX":1,"EDUCATION":2,"MARRIAGE":1,"AGE":57,"PAY_0":-1,"PAY_2":0,"PAY_3":-1,"PAY_4":0,"PAY_5":0,"PAY_6":0,"BILL_AMT1":8617,"BILL_AMT2":5670,"BILL_AMT3":35835,"BILL_AMT4":20940,"BILL_AMT5":19146,"BILL_AMT6":19131,"PAY_AMT1":2000,"PAY_AMT2":36681,"PAY_AMT3":10000,"PAY_AMT4":9000,"PAY_AMT5":689,"PAY_AMT6":679,"default.payment.next.month":0}]},"total_rows":5,"truncation_type":null},"text/plain":"   ID  LIMIT_BAL  SEX  ...  PAY_AMT5  PAY_AMT6  default.payment.next.month\n0   1    20000.0    2  ...       0.0       0.0                           1\n1   2   120000.0    2  ...       0.0    2000.0                           1\n2   3    90000.0    2  ...    1000.0    5000.0                           0\n3   4    50000.0    2  ...    1069.0    1000.0                           0\n4   5    50000.0    1  ...     689.0     679.0                           0\n\n[5 rows x 25 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>LIMIT_BAL</th>\n      <th>SEX</th>\n      <th>EDUCATION</th>\n      <th>MARRIAGE</th>\n      <th>AGE</th>\n      <th>PAY_0</th>\n      <th>PAY_2</th>\n      <th>PAY_3</th>\n      <th>PAY_4</th>\n      <th>PAY_5</th>\n      <th>PAY_6</th>\n      <th>BILL_AMT1</th>\n      <th>BILL_AMT2</th>\n      <th>BILL_AMT3</th>\n      <th>BILL_AMT4</th>\n      <th>BILL_AMT5</th>\n      <th>BILL_AMT6</th>\n      <th>PAY_AMT1</th>\n      <th>PAY_AMT2</th>\n      <th>PAY_AMT3</th>\n      <th>PAY_AMT4</th>\n      <th>PAY_AMT5</th>\n      <th>PAY_AMT6</th>\n      <th>default.payment.next.month</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>20000.0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>24</td>\n      <td>2</td>\n      <td>2</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-2</td>\n      <td>-2</td>\n      <td>3913.0</td>\n      <td>3102.0</td>\n      <td>689.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>689.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>120000.0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>26</td>\n      <td>-1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2682.0</td>\n      <td>1725.0</td>\n      <td>2682.0</td>\n      <td>3272.0</td>\n      <td>3455.0</td>\n      <td>3261.0</td>\n      <td>0.0</td>\n      <td>1000.0</td>\n      <td>1000.0</td>\n      <td>1000.0</td>\n      <td>0.0</td>\n      <td>2000.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>90000.0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>34</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>29239.0</td>\n      <td>14027.0</td>\n      <td>13559.0</td>\n      <td>14331.0</td>\n      <td>14948.0</td>\n      <td>15549.0</td>\n      <td>1518.0</td>\n      <td>1500.0</td>\n      <td>1000.0</td>\n      <td>1000.0</td>\n      <td>1000.0</td>\n      <td>5000.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>50000.0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>37</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>46990.0</td>\n      <td>48233.0</td>\n      <td>49291.0</td>\n      <td>28314.0</td>\n      <td>28959.0</td>\n      <td>29547.0</td>\n      <td>2000.0</td>\n      <td>2019.0</td>\n      <td>1200.0</td>\n      <td>1100.0</td>\n      <td>1069.0</td>\n      <td>1000.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>50000.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>57</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8617.0</td>\n      <td>5670.0</td>\n      <td>35835.0</td>\n      <td>20940.0</td>\n      <td>19146.0</td>\n      <td>19131.0</td>\n      <td>2000.0</td>\n      <td>36681.0</td>\n      <td>10000.0</td>\n      <td>9000.0</td>\n      <td>689.0</td>\n      <td>679.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"source":"# Initializing features\nfeatures = credit_card.drop(['ID','default.payment.next.month'],axis=1).values\n\n# Initializing target\ntarget = credit_card['default.payment.next.month'].values","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# Initializing features\nfeatures = credit_card.drop(['ID','default.payment.next.month'],axis=1).values\n\n# Initializing target\ntarget = credit_card['default.payment.next.month'].values"},"cell_type":"code","id":"b3cf6774-2c52-4f11-b52d-500a9efad33f","execution_count":19,"outputs":[]},{"source":"# Train-test split\nfrom sklearn.model_selection import train_test_split\n\nfeatures_train, features_test, target_train, target_test = train_test_split(features, target,\n                                                                           test_size=0.3,\n                                                                           random_state=42)","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# Train-test split\nfrom sklearn.model_selection import train_test_split\n\nfeatures_train, features_test, target_train, target_test = train_test_split(features, target,\n                                                                           test_size=0.3,\n                                                                           random_state=42)"},"cell_type":"code","id":"f27789bd-58c5-494e-8956-ea162e8833ec","execution_count":20,"outputs":[]},{"source":"# Converting to Tensor\nfeatures_train = tf.constant(features_train)\nfeatures_test = tf.constant(features_test)\n\ntarget_train = tf.Variable(tf.reshape(target_train, (21000,1)))\ntarget_test = tf.Variable(tf.reshape(target_test, (9000,1)))","metadata":{"executionTime":174,"lastSuccessfullyExecutedCode":"# Converting to Tensor\nfeatures_train = tf.constant(features_train)\nfeatures_test = tf.constant(features_test)\n\ntarget_train = tf.Variable(tf.reshape(target_train, (21000,1)))\ntarget_test = tf.Variable(tf.reshape(target_test, (9000,1)))"},"cell_type":"code","id":"bc10128a-55ce-4f9d-9f9d-878f10ff4d2c","execution_count":21,"outputs":[]},{"source":"**Training neural network -- low level**\n- Step 1: Initializing weights and bias\n- Step 2: Define model\n- Step 3: Define loss function -- predicts and calculate loss\n- Step 4: Define optimizer \n- Step 5: Perform minimization with optimizer while training the model","metadata":{},"cell_type":"markdown","id":"3368d30e-a473-4ef8-8ed0-1b65a455b977"},{"source":"# Initializing weights and bias\nw1 = tf.Variable(tf.random.normal([23,7], dtype=tf.float64))\nw2 = tf. Variable(tf.random.normal([7,1], dtype=tf.float64))\n\nb1 = tf.Variable(tf.ones([7], tf.float64))\nb2 = tf.Variable(tf.ones([1], tf.float64))","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# Initializing weights and bias\nw1 = tf.Variable(tf.random.normal([23,7], dtype=tf.float64))\nw2 = tf. Variable(tf.random.normal([7,1], dtype=tf.float64))\n\nb1 = tf.Variable(tf.ones([7], tf.float64))\nb2 = tf.Variable(tf.ones([1], tf.float64))"},"cell_type":"code","id":"1bf49bdc-c5c8-4019-b639-6ad0ec7780e0","execution_count":22,"outputs":[]},{"source":"# Define the model\ndef model(w1, b1, w2, b2, features = features_train):\n\t# Apply relu activation functions to layer 1\n\tlayer1 = tf.keras.activations.relu(tf.matmul(features, w1) + b1)\n    # Apply dropout rate of 0.25\n\tdropout = tf.cast(tf.keras.layers.Dropout(0.25)(layer1), tf.float64)\n\treturn tf.keras.activations.sigmoid(tf.matmul(dropout, w2)+b2)\n\n# Define the loss function\ndef loss_function(w1, b1, w2, b2, features = features_train, targets = target_train):\n\tpredictions = model(w1, b1, w2, b2)\n\t# Pass targets and predictions to the cross entropy loss\n\treturn tf.keras.losses.binary_crossentropy(targets, predictions)","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# Define the model\ndef model(w1, b1, w2, b2, features = features_train):\n\t# Apply relu activation functions to layer 1\n\tlayer1 = tf.keras.activations.relu(tf.matmul(features, w1) + b1)\n    # Apply dropout rate of 0.25\n\tdropout = tf.cast(tf.keras.layers.Dropout(0.25)(layer1), tf.float64)\n\treturn tf.keras.activations.sigmoid(tf.matmul(dropout, w2)+b2)\n\n# Define the loss function\ndef loss_function(w1, b1, w2, b2, features = features_train, targets = target_train):\n\tpredictions = model(w1, b1, w2, b2)\n\t# Pass targets and predictions to the cross entropy loss\n\treturn tf.keras.losses.binary_crossentropy(targets, predictions)"},"cell_type":"code","id":"6530320a-d3c4-41cd-9888-7c0f5665f4f9","execution_count":23,"outputs":[]},{"source":"# Define optimizer\nopt = tf.keras.optimizers.Adam(learning_rate=0.01)","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# Define optimizer\nopt = tf.keras.optimizers.Adam(learning_rate=0.01)"},"cell_type":"code","id":"f6f4d4a1-e56c-4442-b474-4c33d4b495d0","execution_count":24,"outputs":[]},{"source":"# Train the model\nfor j in range(100):\n    # Complete the optimizer\n    opt.minimize(lambda: loss_function(w1, b1, w2, b2), \n                 var_list=[w1, b1, w2, b2])\n    \n    # Print loss at every 10th epoch\n    if j%10 == 0:\n        print(loss_function(w1, b1, w2, b2).numpy())\n        print()","metadata":{"executionTime":119,"lastSuccessfullyExecutedCode":"# Train the model\nfor j in range(100):\n    # Complete the optimizer\n    opt.minimize(lambda: loss_function(w1, b1, w2, b2), \n                 var_list=[w1, b1, w2, b2])\n    \n    # Print loss at every 10th epoch\n    if j%10 == 0:\n        print(loss_function(w1, b1, w2, b2).numpy())\n        print()"},"cell_type":"code","id":"fefe950f-acc5-46a8-9ad6-bf851d66f870","execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":"[     0.              0.              0.         ...  43011.30904631\n 106670.78111379      0.        ]\n\n[    0.             0.             0.         ... 23999.15943046\n 89365.63557881     0.        ]\n\n[    0.             0.             0.         ... 10157.53833998\n 67951.98062886  6781.76606373]\n\n[    0.             0.             0.         ...  3416.50136698\n 23986.49091628 25297.10294247]\n\n[16573.76326877     0.             0.         ...     0.\n 20967.71537493 44518.2150602 ]\n\n[    0.             0.          1652.20464919 ...   564.73766602\n 10625.02078152 30226.00223508]\n\n[    0.             0.             0.         ...  1269.76737942\n 12277.98098992 25567.1894603 ]\n\n[1.68202927e+003 0.00000000e+000 0.00000000e+000 ... 3.46580446e-169\n 7.47488048e+003 2.82528646e+004]\n\n[    0.             0.             0.         ...   385.70156687\n  3796.30715492 23580.14826189]\n\n[3.82240843e+02 0.00000000e+00 0.00000000e+00 ... 7.12366840e-52\n 3.86086005e+02 2.27136867e+04]\n\n"}]},{"source":"# Make predictions with model using test features\nmodel_predictions = model(w1,b1,w2,b2,features_test)\nmodel_predictions = tf.where(model_predictions < 0.5, 0, 1)\n\n# Construct the confusion matrix\nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix(target_test, model_predictions)","metadata":{"executionTime":94,"lastSuccessfullyExecutedCode":"# Make predictions with model using test features\nmodel_predictions = model(w1,b1,w2,b2,features_test)\nmodel_predictions = tf.where(model_predictions < 0.5, 0, 1)\n\n# Construct the confusion matrix\nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix(target_test, model_predictions)"},"cell_type":"code","id":"b004b918-91a4-49dd-8c8b-9455dd4363e9","execution_count":26,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"array([[5455, 1585],\n       [1607,  353]])"},"metadata":{}}]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}