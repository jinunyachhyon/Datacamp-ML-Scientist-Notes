{"cells":[{"source":"# Classification with XGBoost","metadata":{},"cell_type":"markdown","id":"08bff5bf-c5c0-4169-be5b-a14dd105d20b"},{"source":"from sklearn.datasets import load_breast_cancer\nbreast_cancer = load_breast_cancer()\nX = breast_cancer.data\ny = breast_cancer.target","metadata":{"executionTime":59,"lastSuccessfullyExecutedCode":"from sklearn.datasets import load_breast_cancer\nbreast_cancer = load_breast_cancer()\nX = breast_cancer.data\ny = breast_cancer.target"},"cell_type":"code","id":"9a5deb89-cadb-4c09-a673-bf68ca6ef9d6","execution_count":3,"outputs":[]},{"source":"# Import xgboost\nimport xgboost as xgb\n\n# Import necessary modules\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\n# Create the training and test sets\nX_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=123)\n\n# Instantiate the XGBClassifier: xg_cl\nxg_cl = xgb.XGBClassifier(n_estimators=10, objective='binary:logistic', seed=123)\n\n# Fit the classifier to the training set\nxg_cl.fit(X_train,y_train)\n\n# Predict the labels of the test set: preds\npreds = xg_cl.predict(X_test)\n\n# Compute the accuracy: accuracy\naccuracy = float(np.sum(preds==y_test))/y_test.shape[0]\nprint(\"accuracy: %f\" % (accuracy))","metadata":{"executionTime":76,"lastSuccessfullyExecutedCode":"# Import xgboost\nimport xgboost as xgb\n\n# Import necessary modules\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\n# Create the training and test sets\nX_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=123)\n\n# Instantiate the XGBClassifier: xg_cl\nxg_cl = xgb.XGBClassifier(n_estimators=10, objective='binary:logistic', seed=123)\n\n# Fit the classifier to the training set\nxg_cl.fit(X_train,y_train)\n\n# Predict the labels of the test set: preds\npreds = xg_cl.predict(X_test)\n\n# Compute the accuracy: accuracy\naccuracy = float(np.sum(preds==y_test))/y_test.shape[0]\nprint(\"accuracy: %f\" % (accuracy))"},"cell_type":"code","id":"bc7d2399-199d-4b86-8590-54441069e148","execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":"accuracy: 0.956140\n"}]},{"source":"## Cross-validation in XGBoost example","metadata":{},"cell_type":"markdown","id":"089ab7d1-8bad-441e-ba5f-37b9a6ea4bdb"},{"source":"import xgboost as xgb\n\n# for cv in XGBoost, we have to first explicitly convert our data into a DMatrix\nbreast_cancer_matrix = xgb.DMatrix(data=X,\n                                  label=y)\nbreast_cancer_matrix","metadata":{"executionTime":36,"lastSuccessfullyExecutedCode":"import xgboost as xgb\n\n# for cv in XGBoost, we have to first explicitly convert our data into a DMatrix\nbreast_cancer_matrix = xgb.DMatrix(data=X,\n                                  label=y)\nbreast_cancer_matrix"},"cell_type":"code","id":"73b8458b-38c1-424e-ac71-efb32bee56d2","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"<xgboost.core.DMatrix at 0x7fae21efa3a0>"},"metadata":{}}]},{"source":"# parameters to pass into our cross-validation\nparams = {'objective':'binary:logistic',\n         'max_depth':4}\n\n# call cv method and pass DMatrix object storing all the data\ncv_results = xgb.cv(dtrain=breast_cancer_matrix,\n                   params=params,\n                   nfold=4, #no. of cv folds\n                   num_boost_round=10, #no. of trees we want to build\n                   metrics='error', #metric to compute\n                   as_pandas=True) #output to be stored as pandas dataframe\n\nprint(\"CV_results: \\n\",cv_results)\nprint(\"Accuracy: %f\" %((1-cv_results['test-error-mean']).iloc[-1]))","metadata":{"executionTime":204,"lastSuccessfullyExecutedCode":"# parameters to pass into our cross-validation\nparams = {'objective':'binary:logistic',\n         'max_depth':4}\n\n# call cv method and pass DMatrix object storing all the data\ncv_results = xgb.cv(dtrain=breast_cancer_matrix,\n                   params=params,\n                   nfold=4, #no. of cv folds\n                   num_boost_round=10, #no. of trees we want to build\n                   metrics='error', #metric to compute\n                   as_pandas=True) #output to be stored as pandas dataframe\n\nprint(\"CV_results: \\n\",cv_results)\nprint(\"Accuracy: %f\" %((1-cv_results['test-error-mean']).iloc[-1]))"},"cell_type":"code","id":"4f9ebb2f-b3c9-439f-b334-afac92c1bf63","execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":"CV_results: \n    train-error-mean  train-error-std  test-error-mean  test-error-std\n0          0.023432         0.004962         0.072060        0.003127\n1          0.016986         0.004489         0.059761        0.007919\n2          0.011715         0.001648         0.059785        0.011790\n3          0.013472         0.002543         0.059785        0.010687\n4          0.009373         0.000010         0.058049        0.017602\n5          0.007030         0.001656         0.054528        0.017592\n6          0.007030         0.001656         0.052768        0.017675\n7          0.005858         0.001168         0.052768        0.017675\n8          0.005272         0.001013         0.052768        0.017675\n9          0.004100         0.001941         0.047498        0.017573\nAccuracy: 0.952502\n"}]},{"source":"## When to use XGBoost\n- Greater than 1000 training samples and less 100 features\n- The number of features < number of training samples\n- mixture of categorical and numerical features\n\n## When to NOT use XGBoost\n- Image recognition\n- Computer vision\n- Natural Language Processing and understanding problems","metadata":{},"cell_type":"markdown","id":"1eb9a299-433b-4627-b09b-bfc7c93e7bb7"}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataCamp Workspace"},"nbformat":4,"nbformat_minor":5}