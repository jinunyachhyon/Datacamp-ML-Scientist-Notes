{"cells":[{"source":"# Early stopping: Optimizing the optimization\n\n- You can use early stopping to stop optimization when it isn't helping any more. Since the optimization stops automatically when it isn't helping, you can also set a high value for `epochs` in your call to `.fit()`.","metadata":{},"cell_type":"markdown","id":"e5c53f27-06f8-424f-a247-19e48afc27c7"},{"source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\n# Import titanic data\ntitanic = pd.read_csv('datasets/titanic_all_numeric.csv')\ntitanic.head()","metadata":{"executionTime":1891,"lastSuccessfullyExecutedCode":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\n# Import titanic data\ntitanic = pd.read_csv('datasets/titanic_all_numeric.csv')\ntitanic.head()"},"cell_type":"code","id":"d90cba52-987c-4fbb-9fdf-be1cd6b3414a","execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":"2023-05-24 17:33:54.058556: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2023-05-24 17:33:54.058580: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"},{"output_type":"execute_result","execution_count":1,"data":{"application/com.datacamp.data-table.v1+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"survived","type":"integer"},{"name":"pclass","type":"integer"},{"name":"age","type":"number"},{"name":"sibsp","type":"integer"},{"name":"parch","type":"integer"},{"name":"fare","type":"number"},{"name":"male","type":"integer"},{"name":"age_was_missing","type":"boolean"},{"name":"embarked_from_cherbourg","type":"integer"},{"name":"embarked_from_queenstown","type":"integer"},{"name":"embarked_from_southampton","type":"integer"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":[{"index":0,"survived":0,"pclass":3,"age":22,"sibsp":1,"parch":0,"fare":7.25,"male":1,"age_was_missing":false,"embarked_from_cherbourg":0,"embarked_from_queenstown":0,"embarked_from_southampton":1},{"index":1,"survived":1,"pclass":1,"age":38,"sibsp":1,"parch":0,"fare":71.2833,"male":0,"age_was_missing":false,"embarked_from_cherbourg":1,"embarked_from_queenstown":0,"embarked_from_southampton":0},{"index":2,"survived":1,"pclass":3,"age":26,"sibsp":0,"parch":0,"fare":7.925,"male":0,"age_was_missing":false,"embarked_from_cherbourg":0,"embarked_from_queenstown":0,"embarked_from_southampton":1},{"index":3,"survived":1,"pclass":1,"age":35,"sibsp":1,"parch":0,"fare":53.1,"male":0,"age_was_missing":false,"embarked_from_cherbourg":0,"embarked_from_queenstown":0,"embarked_from_southampton":1},{"index":4,"survived":0,"pclass":3,"age":35,"sibsp":0,"parch":0,"fare":8.05,"male":1,"age_was_missing":false,"embarked_from_cherbourg":0,"embarked_from_queenstown":0,"embarked_from_southampton":1}]},"total_rows":5,"truncation_type":null},"text/plain":"   survived  pclass  ...  embarked_from_queenstown  embarked_from_southampton\n0         0       3  ...                         0                          1\n1         1       1  ...                         0                          0\n2         1       3  ...                         0                          1\n3         1       1  ...                         0                          1\n4         0       3  ...                         0                          1\n\n[5 rows x 11 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>survived</th>\n      <th>pclass</th>\n      <th>age</th>\n      <th>sibsp</th>\n      <th>parch</th>\n      <th>fare</th>\n      <th>male</th>\n      <th>age_was_missing</th>\n      <th>embarked_from_cherbourg</th>\n      <th>embarked_from_queenstown</th>\n      <th>embarked_from_southampton</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>3</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>0</td>\n      <td>False</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>0</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>0</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>3</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"source":"# Initialize features and labels\nfeatures = np.array(titanic.drop('survived', axis=1), dtype = np.float32)\nlabels = np.array(pd.get_dummies(titanic['survived']), dtype= np.float32)","metadata":{"executionTime":54,"lastSuccessfullyExecutedCode":"# Initialize features and labels\nfeatures = np.array(titanic.drop('survived', axis=1), dtype = np.float32)\nlabels = np.array(pd.get_dummies(titanic['survived']), dtype= np.float32)"},"cell_type":"code","id":"dfcdf9f2-374a-43ea-9c9c-8c6f989f2a4b","execution_count":2,"outputs":[]},{"source":"# Train test split\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(features, labels,\n                                                   test_size=0.3,\n                                                   random_state=42)","metadata":{"executionTime":84,"lastSuccessfullyExecutedCode":"# Train test split\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(features, labels,\n                                                   test_size=0.3,\n                                                   random_state=42)"},"cell_type":"code","id":"76a1846d-762a-42d6-876d-46828c3d44b5","execution_count":5,"outputs":[]},{"source":"# Total features\nn_cols = features.shape[1]\nn_cols","metadata":{"executionTime":92,"lastSuccessfullyExecutedCode":"# Total features\nn_cols = features.shape[1]\nn_cols"},"cell_type":"code","id":"d3be4f7d-84a5-40c3-ad84-fa48ec8e3806","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"10"},"metadata":{}}]},{"source":"from tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Sequential\n\n# Specifying model architecture\nmodel = Sequential()\n\n# Add hidden layers\nmodel.add(Dense(16, activation='relu', input_shape=(n_cols,)))\nmodel.add(Dense(8, activation='relu'))\nmodel.add(Dense(4, activation='relu'))\n\n# Output layer\nmodel.add(Dense(2, activation='softmax'))\n\n# Model summary\nmodel.summary()","metadata":{"executionTime":361,"lastSuccessfullyExecutedCode":"from tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Sequential\n\n# Specifying model architecture\nmodel = Sequential()\n\n# Add hidden layers\nmodel.add(Dense(16, activation='relu', input_shape=(n_cols,)))\nmodel.add(Dense(8, activation='relu'))\nmodel.add(Dense(4, activation='relu'))\n\n# Output layer\nmodel.add(Dense(2, activation='softmax'))\n\n# Model summary\nmodel.summary()"},"cell_type":"code","id":"a841f436-8c95-4ec2-9514-2540ac87ee35","execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense_4 (Dense)             (None, 16)                176       \n                                                                 \n dense_5 (Dense)             (None, 8)                 136       \n                                                                 \n dense_6 (Dense)             (None, 4)                 36        \n                                                                 \n dense_7 (Dense)             (None, 2)                 10        \n                                                                 \n=================================================================\nTotal params: 358\nTrainable params: 358\nNon-trainable params: 0\n_________________________________________________________________\n"}]},{"source":"# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"executionTime":99,"lastSuccessfullyExecutedCode":"# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"},"cell_type":"code","id":"f09f7538-767d-47b5-a642-873fcd8f5350","execution_count":11,"outputs":[]},{"source":"# Early Stopping while fitting \nfrom tensorflow.keras.callbacks import EarlyStopping\n\n# Define early_stopping_monitor -- Stop optimization when the validation loss hasn't improved for 2 epochs by specifying the patience parameter of EarlyStopping() to be 2\nearly_stopping_monitor = EarlyStopping(patience=2)\n\n# Fit the model\nmodel.fit(X_train, y_train, epochs=30, validation_split=0.3, callbacks=[early_stopping_monitor])","metadata":{"executionTime":1894,"lastSuccessfullyExecutedCode":"# Early Stopping while fitting \nfrom tensorflow.keras.callbacks import EarlyStopping\n\n# Define early_stopping_monitor -- Stop optimization when the validation loss hasn't improved for 2 epochs by specifying the patience parameter of EarlyStopping() to be 2\nearly_stopping_monitor = EarlyStopping(patience=2)\n\n# Fit the model\nmodel.fit(X_train, y_train, epochs=30, validation_split=0.3, callbacks=[early_stopping_monitor])"},"cell_type":"code","id":"17a96d6b-f634-47b4-bb18-ea2b4650ce26","execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":"Epoch 1/30\n14/14 [==============================] - 0s 10ms/step - loss: 0.6508 - accuracy: 0.6261 - val_loss: 0.6455 - val_accuracy: 0.6364\nEpoch 2/30\n14/14 [==============================] - 0s 2ms/step - loss: 0.6265 - accuracy: 0.6261 - val_loss: 0.6314 - val_accuracy: 0.6364\nEpoch 3/30\n14/14 [==============================] - 0s 2ms/step - loss: 0.6161 - accuracy: 0.6261 - val_loss: 0.6248 - val_accuracy: 0.6364\nEpoch 4/30\n14/14 [==============================] - 0s 2ms/step - loss: 0.6097 - accuracy: 0.6261 - val_loss: 0.6201 - val_accuracy: 0.6364\nEpoch 5/30\n14/14 [==============================] - 0s 2ms/step - loss: 0.6070 - accuracy: 0.6261 - val_loss: 0.6167 - val_accuracy: 0.6364\nEpoch 6/30\n14/14 [==============================] - 0s 2ms/step - loss: 0.6032 - accuracy: 0.6261 - val_loss: 0.6128 - val_accuracy: 0.6524\nEpoch 7/30\n14/14 [==============================] - 0s 2ms/step - loss: 0.6002 - accuracy: 0.7248 - val_loss: 0.6060 - val_accuracy: 0.6578\nEpoch 8/30\n14/14 [==============================] - 0s 2ms/step - loss: 0.5983 - accuracy: 0.7133 - val_loss: 0.6049 - val_accuracy: 0.6578\nEpoch 9/30\n14/14 [==============================] - 0s 2ms/step - loss: 0.5935 - accuracy: 0.7248 - val_loss: 0.5962 - val_accuracy: 0.6631\nEpoch 10/30\n14/14 [==============================] - 0s 2ms/step - loss: 0.5917 - accuracy: 0.7339 - val_loss: 0.5997 - val_accuracy: 0.6578\nEpoch 11/30\n14/14 [==============================] - 0s 2ms/step - loss: 0.5875 - accuracy: 0.7156 - val_loss: 0.5901 - val_accuracy: 0.6791\nEpoch 12/30\n14/14 [==============================] - 0s 2ms/step - loss: 0.5888 - accuracy: 0.7294 - val_loss: 0.5831 - val_accuracy: 0.6898\nEpoch 13/30\n14/14 [==============================] - 0s 2ms/step - loss: 0.5774 - accuracy: 0.7225 - val_loss: 0.5898 - val_accuracy: 0.6578\nEpoch 14/30\n14/14 [==============================] - 0s 4ms/step - loss: 0.5770 - accuracy: 0.7156 - val_loss: 0.5771 - val_accuracy: 0.6952\nEpoch 15/30\n14/14 [==============================] - 0s 2ms/step - loss: 0.5724 - accuracy: 0.7408 - val_loss: 0.5803 - val_accuracy: 0.6738\nEpoch 16/30\n14/14 [==============================] - 0s 2ms/step - loss: 0.5688 - accuracy: 0.7362 - val_loss: 0.5718 - val_accuracy: 0.6952\nEpoch 17/30\n14/14 [==============================] - 0s 2ms/step - loss: 0.5649 - accuracy: 0.7408 - val_loss: 0.5724 - val_accuracy: 0.6791\nEpoch 18/30\n14/14 [==============================] - 0s 2ms/step - loss: 0.5639 - accuracy: 0.7248 - val_loss: 0.5644 - val_accuracy: 0.7112\nEpoch 19/30\n14/14 [==============================] - 0s 2ms/step - loss: 0.5712 - accuracy: 0.7317 - val_loss: 0.5612 - val_accuracy: 0.7059\nEpoch 20/30\n14/14 [==============================] - 0s 2ms/step - loss: 0.5589 - accuracy: 0.7385 - val_loss: 0.5616 - val_accuracy: 0.6952\nEpoch 21/30\n14/14 [==============================] - 0s 2ms/step - loss: 0.5518 - accuracy: 0.7523 - val_loss: 0.5567 - val_accuracy: 0.7112\nEpoch 22/30\n14/14 [==============================] - 0s 2ms/step - loss: 0.5516 - accuracy: 0.7339 - val_loss: 0.5540 - val_accuracy: 0.7059\nEpoch 23/30\n14/14 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.7477 - val_loss: 0.5598 - val_accuracy: 0.6898\nEpoch 24/30\n14/14 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.7385 - val_loss: 0.5512 - val_accuracy: 0.6791\nEpoch 25/30\n14/14 [==============================] - 0s 2ms/step - loss: 0.5509 - accuracy: 0.7546 - val_loss: 0.5536 - val_accuracy: 0.6952\nEpoch 26/30\n14/14 [==============================] - 0s 2ms/step - loss: 0.5393 - accuracy: 0.7431 - val_loss: 0.5438 - val_accuracy: 0.7059\nEpoch 27/30\n14/14 [==============================] - 0s 2ms/step - loss: 0.5388 - accuracy: 0.7385 - val_loss: 0.5500 - val_accuracy: 0.6952\nEpoch 28/30\n14/14 [==============================] - 0s 2ms/step - loss: 0.5321 - accuracy: 0.7569 - val_loss: 0.5386 - val_accuracy: 0.7112\nEpoch 29/30\n14/14 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.7615 - val_loss: 0.5342 - val_accuracy: 0.7219\nEpoch 30/30\n14/14 [==============================] - 0s 2ms/step - loss: 0.5295 - accuracy: 0.7638 - val_loss: 0.5424 - val_accuracy: 0.6952\n"},{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"<keras.callbacks.History at 0x7fc084120520>"},"metadata":{}}]},{"source":"Though specified epochs of 30, the training stopped at epoch 14 since the accuracy was not improving every since. This allowed to specify higher epochs without worrying for computational cost and also with this you don't have to guess the epoch as the training stops automatically at optimal point.","metadata":{},"cell_type":"markdown","id":"ef2b7af7-feee-438c-a913-71b67be4fc2b"},{"source":"# Predict on test data\npred = model.predict(X_test)\n\n# Convert into binary prediction\nbi_pred = np.where(pred>0.5, 1, 0)","metadata":{"executionTime":178,"lastSuccessfullyExecutedCode":"# Predict on test data\npred = model.predict(X_test)\n\n# Convert into binary prediction\nbi_pred = np.where(pred>0.5, 1, 0)"},"cell_type":"code","id":"6b0eac60-19c0-4824-a53d-e2cdfe6c0d13","execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":"9/9 [==============================] - 0s 775us/step\n"}]},{"source":"# Compute accuracy\nfrom sklearn.metrics import accuracy_score\n\naccuracy_score(y_test, bi_pred)","metadata":{"executionTime":141,"lastSuccessfullyExecutedCode":"# Compute accuracy\nfrom sklearn.metrics import accuracy_score\n\naccuracy_score(y_test, bi_pred)"},"cell_type":"code","id":"c600dfe2-d35e-4f90-a558-b630ab25cbac","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"0.6902985074626866"},"metadata":{}}]},{"source":"# Building digit recognition model","metadata":{},"cell_type":"markdown","id":"9197fff7-a37e-4cbc-bf56-dc5b8e656638"},{"source":"mnist = pd.read_csv('datasets/mnist.csv', header=None)\nmnist.shape","metadata":{"executionTime":209,"lastSuccessfullyExecutedCode":"mnist = pd.read_csv('datasets/mnist.csv', header=None)\nmnist.shape"},"cell_type":"code","id":"8455e2d2-501c-4216-9df9-6336505451a9","execution_count":53,"outputs":[{"output_type":"execute_result","execution_count":53,"data":{"text/plain":"(2001, 785)"},"metadata":{}}]},{"source":"# Features and labels\nfeatures_mnist = np.array(mnist.drop(0,axis=1),dtype = np.float32)\nlabels_mnist = np.array(pd.get_dummies(mnist[0], dtype = np.float32)) ","metadata":{"executionTime":314,"lastSuccessfullyExecutedCode":"# Features and labels\nfeatures_mnist = np.array(mnist.drop(0,axis=1),dtype = np.float32)\nlabels_mnist = np.array(pd.get_dummies(mnist[0], dtype = np.float32)) "},"cell_type":"code","id":"b6442013-0eb8-4590-93d5-c7cb5ab60996","execution_count":54,"outputs":[]},{"source":"# Train-test split\nX_train_mn, X_test_mn, y_train_mn, y_test_mn = train_test_split(features_mnist, labels_mnist,\n                                                               test_size=0.3, random_state=42)","metadata":{"executionTime":434,"lastSuccessfullyExecutedCode":"# Train-test split\nX_train_mn, X_test_mn, y_train_mn, y_test_mn = train_test_split(features_mnist, labels_mnist,\n                                                               test_size=0.3, random_state=42)"},"cell_type":"code","id":"d560d5db-1c70-47c6-b386-e624d52efece","execution_count":55,"outputs":[]},{"source":"# Specify model architecture\nmodel_mnist = Sequential()\n\n# Add hidden layers\nmodel_mnist.add(Dense(64, activation='relu', input_shape=(784,)))\nmodel_mnist.add(Dense(64, activation='relu'))\n\n# Output layer\nmodel_mnist.add(Dense(10, activation='softmax'))\n\n# Model summary\nmodel_mnist.summary()","metadata":{"executionTime":385,"lastSuccessfullyExecutedCode":"# Specify model architecture\nmodel_mnist = Sequential()\n\n# Add hidden layers\nmodel_mnist.add(Dense(64, activation='relu', input_shape=(784,)))\nmodel_mnist.add(Dense(64, activation='relu'))\n\n# Output layer\nmodel_mnist.add(Dense(10, activation='softmax'))\n\n# Model summary\nmodel_mnist.summary()"},"cell_type":"code","id":"50b02f2a-5f32-4458-b9ca-11b32ec7e1bc","execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":"Model: \"sequential_11\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense_42 (Dense)            (None, 64)                50240     \n                                                                 \n dense_43 (Dense)            (None, 64)                4160      \n                                                                 \n dense_44 (Dense)            (None, 10)                650       \n                                                                 \n=================================================================\nTotal params: 55,050\nTrainable params: 55,050\nNon-trainable params: 0\n_________________________________________________________________\n"}]},{"source":"# Compile model\nmodel_mnist.compile(optimizer=tf.keras.optimizers.Adam(0.01), #<-- lr = 0.01\n                    loss='categorical_crossentropy',\n                    metrics=['accuracy'])","metadata":{"executionTime":200,"lastSuccessfullyExecutedCode":"# Compile model\nmodel_mnist.compile(optimizer=tf.keras.optimizers.Adam(0.01), #<-- lr = 0.01\n                    loss='categorical_crossentropy',\n                    metrics=['accuracy'])"},"cell_type":"code","id":"1aeb2afb-25b6-4f4d-a070-926db5891907","execution_count":67,"outputs":[]},{"source":"# Early stopping\nearly_stopping_monitor_mnist = EarlyStopping(patience=3)","metadata":{"executionTime":301,"lastSuccessfullyExecutedCode":"# Early stopping\nearly_stopping_monitor_mnist = EarlyStopping(patience=3)"},"cell_type":"code","id":"2124a653-4e13-4777-a0e1-051bb2f6d93a","execution_count":69,"outputs":[]},{"source":"# Fit the model on training set\nmodel_mnist.fit(X_train_mn, y_train_mn, \n                epochs=30, \n                validation_split=0.2,\n                callbacks=[early_stopping_monitor_mnist])","metadata":{"executionTime":681,"lastSuccessfullyExecutedCode":"# Fit the model on training set\nmodel_mnist.fit(X_train_mn, y_train_mn, \n                epochs=30, \n                validation_split=0.2,\n                callbacks=[early_stopping_monitor_mnist])"},"cell_type":"code","id":"f54d5f03-dc75-4bdb-903f-6ad444d33fc7","execution_count":70,"outputs":[{"output_type":"stream","name":"stdout","text":"Epoch 1/30\n35/35 [==============================] - 0s 2ms/step - loss: 1.2695 - accuracy: 0.5696 - val_loss: 1.7705 - val_accuracy: 0.5571\nEpoch 2/30\n35/35 [==============================] - 0s 2ms/step - loss: 1.1938 - accuracy: 0.5643 - val_loss: 1.4617 - val_accuracy: 0.5536\nEpoch 3/30\n35/35 [==============================] - 0s 2ms/step - loss: 1.0834 - accuracy: 0.6098 - val_loss: 1.8406 - val_accuracy: 0.6036\nEpoch 4/30\n35/35 [==============================] - 0s 2ms/step - loss: 1.0640 - accuracy: 0.6393 - val_loss: 1.5760 - val_accuracy: 0.5857\nEpoch 5/30\n35/35 [==============================] - 0s 2ms/step - loss: 1.0230 - accuracy: 0.6670 - val_loss: 1.6953 - val_accuracy: 0.6036\n"},{"output_type":"execute_result","execution_count":70,"data":{"text/plain":"<keras.callbacks.History at 0x7fbff4213d90>"},"metadata":{}}]},{"source":"# Predict the test set\npred_mnist = model_mnist.predict(X_test_mn)","metadata":{"executionTime":301,"lastSuccessfullyExecutedCode":"# Predict the test set\npred_mnist = model_mnist.predict(X_test_mn)"},"cell_type":"code","id":"74fc5fcd-91c6-420e-ae00-4fd8f3fb61b5","execution_count":77,"outputs":[{"output_type":"stream","name":"stdout","text":"19/19 [==============================] - 0s 739us/step\n"}]},{"source":"# Find the indices of the maximum values along each row\nmax_indices = np.argmax(pred_mnist, axis=1)\n\n# Create a new array with all values set to 0\nresult = np.zeros_like(pred_mnist)\n\n# Set the maximum value in each row to 1\nresult[np.arange(len(pred_mnist)), max_indices] = 1\n\n# Print the result -- binary representation of predicted output\nprint(result)","metadata":{"executionTime":444,"lastSuccessfullyExecutedCode":"# Find the indices of the maximum values along each row\nmax_indices = np.argmax(pred_mnist, axis=1)\n\n# Create a new array with all values set to 0\nresult = np.zeros_like(pred_mnist)\n\n# Set the maximum value in each row to 1\nresult[np.arange(len(pred_mnist)), max_indices] = 1\n\n# Print the result -- binary representation of predicted output\nprint(result)"},"cell_type":"code","id":"f4caf4c3-362e-44f8-86dd-2022d6e00065","execution_count":84,"outputs":[{"output_type":"stream","name":"stdout","text":"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 1. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 1. 0.]\n [1. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 1. 0.]]\n"}]},{"source":"result[4]","metadata":{"executionTime":215,"lastSuccessfullyExecutedCode":"result[4]"},"cell_type":"code","id":"a2f92f07-047e-40a6-aa40-f34067eaeb15","execution_count":85,"outputs":[{"output_type":"execute_result","execution_count":85,"data":{"text/plain":"array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"},"metadata":{}}]},{"source":"# Compute accuracy\naccuracy_score(y_test_mn,result)","metadata":{"executionTime":168,"lastSuccessfullyExecutedCode":"# Compute accuracy\naccuracy_score(y_test_mn,result)"},"cell_type":"code","id":"35890bc3-a6fa-4cc8-b4dd-68c3585a6a89","execution_count":92,"outputs":[{"output_type":"execute_result","execution_count":92,"data":{"text/plain":"0.5557404326123128"},"metadata":{}}]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}