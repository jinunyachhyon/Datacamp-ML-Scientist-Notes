{"cells":[{"source":"# The Bias-Variance Tradeoff","metadata":{},"cell_type":"markdown","id":"0e6531c9-46d8-4b50-91bf-a04857c76f93"},{"source":"## Generalization Error","metadata":{},"cell_type":"markdown","id":"d4bab008-761a-4441-aafe-0d984f8632ef"},{"source":"**Overfitting**\n\n![image-4](image-4.png)\n\nThe model clearly memorized the noise present in the training set. Such model achieves a low training set error and a high test set error.","metadata":{},"cell_type":"markdown","id":"a2623a63-9da0-41b6-a9a3-c17bc9badbd3"},{"source":"**Underfitting**\n\n![image-5](image-5.png)\n\nIn such model, training set error is roughly equal to test set error. However, both errors are relatively high.","metadata":{},"cell_type":"markdown","id":"65aee47a-feb7-4776-b7c6-9301f44525f9"},{"source":"**Generalization Error**\n\n![image-6](image-6.png)\n\n- Higher the bias, underfit the model\n- Higher the variance, overfit the model\n\n![image-7](image-7.png)\n","metadata":{},"cell_type":"markdown","id":"d5ab6326-e6ae-4c70-a0a0-47cf581a70d7"},{"source":"## Diagnose bias and variance problems","metadata":{},"cell_type":"markdown","id":"c3a36ba6-b6cf-49b3-9743-dfd493a6c351"},{"source":"**K-Fold CV**\n\n![image-8](image-8.png)\n\nCV error = (E1+E2+...+E10)/10\n\n- **High variance** : CV error > training set error\n- **High bias** : CV error nearly= training set error, but much greater than the desired error ","metadata":{},"cell_type":"markdown","id":"047228a6-b060-4e10-b0d5-86a4be3f1797"},{"source":"import pandas as pd\nauto = pd.read_csv('datasets/auto.csv')\nauto.head()","metadata":{"executionTime":188,"lastSuccessfullyExecutedCode":"import pandas as pd\nauto = pd.read_csv('datasets/auto.csv')\nauto.head()"},"cell_type":"code","id":"ca501303-4510-4d0e-a6fd-9f349e4936ef","execution_count":1,"outputs":[{"output_type":"execute_result","execution_count":1,"data":{"application/com.datacamp.data-table.v1+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"mpg","type":"number"},{"name":"displ","type":"number"},{"name":"hp","type":"integer"},{"name":"weight","type":"integer"},{"name":"accel","type":"number"},{"name":"origin","type":"string"},{"name":"size","type":"number"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":[{"index":0,"mpg":18,"displ":250,"hp":88,"weight":3139,"accel":14.5,"origin":"US","size":15},{"index":1,"mpg":9,"displ":304,"hp":193,"weight":4732,"accel":18.5,"origin":"US","size":20},{"index":2,"mpg":36.1,"displ":91,"hp":60,"weight":1800,"accel":16.4,"origin":"Asia","size":10},{"index":3,"mpg":18.5,"displ":250,"hp":98,"weight":3525,"accel":19,"origin":"US","size":15},{"index":4,"mpg":34.3,"displ":97,"hp":78,"weight":2188,"accel":15.8,"origin":"Europe","size":10}]},"total_rows":5,"truncation_type":null},"text/plain":"    mpg  displ   hp  weight  accel  origin  size\n0  18.0  250.0   88    3139   14.5      US  15.0\n1   9.0  304.0  193    4732   18.5      US  20.0\n2  36.1   91.0   60    1800   16.4    Asia  10.0\n3  18.5  250.0   98    3525   19.0      US  15.0\n4  34.3   97.0   78    2188   15.8  Europe  10.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mpg</th>\n      <th>displ</th>\n      <th>hp</th>\n      <th>weight</th>\n      <th>accel</th>\n      <th>origin</th>\n      <th>size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>18.0</td>\n      <td>250.0</td>\n      <td>88</td>\n      <td>3139</td>\n      <td>14.5</td>\n      <td>US</td>\n      <td>15.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9.0</td>\n      <td>304.0</td>\n      <td>193</td>\n      <td>4732</td>\n      <td>18.5</td>\n      <td>US</td>\n      <td>20.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>36.1</td>\n      <td>91.0</td>\n      <td>60</td>\n      <td>1800</td>\n      <td>16.4</td>\n      <td>Asia</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>18.5</td>\n      <td>250.0</td>\n      <td>98</td>\n      <td>3525</td>\n      <td>19.0</td>\n      <td>US</td>\n      <td>15.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>34.3</td>\n      <td>97.0</td>\n      <td>78</td>\n      <td>2188</td>\n      <td>15.8</td>\n      <td>Europe</td>\n      <td>10.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"source":"# separating data into explanatory and response data\nX = auto.drop(['mpg','hp','weight','accel','origin','size'],axis=1)\ny = auto['mpg']","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# separating data into explanatory and response data\nX = auto.drop(['mpg','hp','weight','accel','origin','size'],axis=1)\ny = auto['mpg']"},"cell_type":"code","id":"6d2c2f73-d69b-47de-a4e5-886094e0fe07","execution_count":2,"outputs":[]},{"source":"from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error as MSE\nfrom sklearn.model_selection import cross_val_score\n\n# Set seed for reproducibility\nSEED = 123\n\n# Split data into 70% train and 30% test\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=SEED)\n\n# Instantiate decision tree regressor \ndt = DecisionTreeRegressor(max_depth=4,\n                          min_samples_leaf=0.14,\n                          random_state=SEED)\n","metadata":{"executionTime":151,"lastSuccessfullyExecutedCode":"from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error as MSE\nfrom sklearn.model_selection import cross_val_score\n\n# Set seed for reproducibility\nSEED = 123\n\n# Split data into 70% train and 30% test\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=SEED)\n\n# Instantiate decision tree regressor \ndt = DecisionTreeRegressor(max_depth=4,\n                          min_samples_leaf=0.14,\n                          random_state=SEED)\n"},"cell_type":"code","id":"f14b0182-9ba7-4796-b49a-ad983bc432e9","execution_count":3,"outputs":[]},{"source":"# Evaluate the list of MSE obtained by 10-fold CV\n# Set n_jobs to -1 in order to exploit all CPU cores in computation\nMSE_CV = - cross_val_score(dt, X_train, y_train, cv=10,\n                          scoring = 'neg_mean_squared_error',\n                          n_jobs = -1)\nMSE_CV","metadata":{"executionTime":1182,"lastSuccessfullyExecutedCode":"# Evaluate the list of MSE obtained by 10-fold CV\n# Set n_jobs to -1 in order to exploit all CPU cores in computation\nMSE_CV = - cross_val_score(dt, X_train, y_train, cv=10,\n                          scoring = 'neg_mean_squared_error',\n                          n_jobs = -1)\nMSE_CV"},"cell_type":"code","id":"332f38e9-4173-4419-8a3b-bec0e68ebd33","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"array([16.33824557, 19.71569647, 20.47204676, 19.32346373, 17.7182428 ,\n       20.90288889, 25.60983091, 15.84346118, 22.69564507, 20.80819754])"},"metadata":{}}]},{"source":"# Fit 'dt' to the training set\ndt.fit(X_train, y_train)\n# Predict the labels of training set\ny_predict_train = dt.predict(X_train)\n# Predict the labels on test set\ny_predict_test = dt.predict(X_test)","metadata":{"executionTime":50,"lastSuccessfullyExecutedCode":"# Fit 'dt' to the training set\ndt.fit(X_train, y_train)\n# Predict the labels of training set\ny_predict_train = dt.predict(X_train)\n# Predict the labels on test set\ny_predict_test = dt.predict(X_test)"},"cell_type":"code","id":"16dab64e-bb4b-446c-b26e-7c4b606bff5f","execution_count":5,"outputs":[]},{"source":"# CV MSE \nprint('CV MSE: {:.2F}'.format(MSE_CV.mean()))\n\n# Training set MSE \nprint('Train MSE: {:.2F}'.format(MSE(y_train, y_predict_train)))\n\n# Test set MSE \nprint('Test MSE: {:.2F}'.format(MSE(y_test, y_predict_test)))","metadata":{"executionTime":23,"lastSuccessfullyExecutedCode":"# CV MSE \nprint('CV MSE: {:.2F}'.format(MSE_CV.mean()))\n\n# Training set MSE \nprint('Train MSE: {:.2F}'.format(MSE(y_train, y_predict_train)))\n\n# Test set MSE \nprint('Test MSE: {:.2F}'.format(MSE(y_test, y_predict_test)))"},"cell_type":"code","id":"0c221491-611e-45ba-a817-cfe73acacaa3","execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":"CV MSE: 19.94\nTrain MSE: 17.89\nTest MSE: 20.41\n"}]},{"source":"Given that the training set error is smaller than the CV-error, we can deduce that dt overfits the training set and that it suffers from high variance.","metadata":{},"cell_type":"markdown","id":"d3efeda8-0b4f-4b9c-b050-7893c5596358"},{"source":"## Ensemble Learning\n- Limitation od CARTs --> High Variance, unconstrained CARTs may overfit the training set\n- Solution: ensemble learning\n\n![image-9](image-9.png)\n","metadata":{},"cell_type":"markdown","id":"bd46b85b-e754-4270-bd8e-231a03820b1c"},{"source":"### Ensemble Learning: Voting Classifier\n\n![image-10](image-10.png)\n","metadata":{},"cell_type":"markdown","id":"9e184e68-f263-484d-b971-7f8f82d1382d"},{"source":"breast_cancer = pd.read_csv('datasets/wbc.csv')\nbreast_cancer.head()","metadata":{"executionTime":327,"lastSuccessfullyExecutedCode":"breast_cancer = pd.read_csv('datasets/wbc.csv')\nbreast_cancer.head()"},"cell_type":"code","id":"f6f714d9-4721-4f80-b12c-ba6be32982ab","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"application/com.datacamp.data-table.v1+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"id","type":"integer"},{"name":"diagnosis","type":"string"},{"name":"radius_mean","type":"number"},{"name":"texture_mean","type":"number"},{"name":"perimeter_mean","type":"number"},{"name":"area_mean","type":"number"},{"name":"smoothness_mean","type":"number"},{"name":"compactness_mean","type":"number"},{"name":"concavity_mean","type":"number"},{"name":"concave points_mean","type":"number"},{"name":"symmetry_mean","type":"number"},{"name":"fractal_dimension_mean","type":"number"},{"name":"radius_se","type":"number"},{"name":"texture_se","type":"number"},{"name":"perimeter_se","type":"number"},{"name":"area_se","type":"number"},{"name":"smoothness_se","type":"number"},{"name":"compactness_se","type":"number"},{"name":"concavity_se","type":"number"},{"name":"concave points_se","type":"number"},{"name":"symmetry_se","type":"number"},{"name":"fractal_dimension_se","type":"number"},{"name":"radius_worst","type":"number"},{"name":"texture_worst","type":"number"},{"name":"perimeter_worst","type":"number"},{"name":"area_worst","type":"number"},{"name":"smoothness_worst","type":"number"},{"name":"compactness_worst","type":"number"},{"name":"concavity_worst","type":"number"},{"name":"concave points_worst","type":"number"},{"name":"symmetry_worst","type":"number"},{"name":"fractal_dimension_worst","type":"number"},{"name":"Unnamed: 32","type":"number"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":[{"index":0,"id":842302,"diagnosis":"M","radius_mean":17.99,"texture_mean":10.38,"perimeter_mean":122.8,"area_mean":1001,"smoothness_mean":0.1184,"compactness_mean":0.2776,"concavity_mean":0.3001,"concave points_mean":0.1471,"symmetry_mean":0.2419,"fractal_dimension_mean":0.07871,"radius_se":1.095,"texture_se":0.9053,"perimeter_se":8.589,"area_se":153.4,"smoothness_se":0.006399,"compactness_se":0.04904,"concavity_se":0.05373,"concave points_se":0.01587,"symmetry_se":0.03003,"fractal_dimension_se":0.006193,"radius_worst":25.38,"texture_worst":17.33,"perimeter_worst":184.6,"area_worst":2019,"smoothness_worst":0.1622,"compactness_worst":0.6656,"concavity_worst":0.7119,"concave points_worst":0.2654,"symmetry_worst":0.4601,"fractal_dimension_worst":0.1189,"Unnamed: 32":null},{"index":1,"id":842517,"diagnosis":"M","radius_mean":20.57,"texture_mean":17.77,"perimeter_mean":132.9,"area_mean":1326,"smoothness_mean":0.08474,"compactness_mean":0.07864,"concavity_mean":0.0869,"concave points_mean":0.07017,"symmetry_mean":0.1812,"fractal_dimension_mean":0.05667,"radius_se":0.5435,"texture_se":0.7339,"perimeter_se":3.398,"area_se":74.08,"smoothness_se":0.005225,"compactness_se":0.01308,"concavity_se":0.0186,"concave points_se":0.0134,"symmetry_se":0.01389,"fractal_dimension_se":0.003532,"radius_worst":24.99,"texture_worst":23.41,"perimeter_worst":158.8,"area_worst":1956,"smoothness_worst":0.1238,"compactness_worst":0.1866,"concavity_worst":0.2416,"concave points_worst":0.186,"symmetry_worst":0.275,"fractal_dimension_worst":0.08902,"Unnamed: 32":null},{"index":2,"id":84300903,"diagnosis":"M","radius_mean":19.69,"texture_mean":21.25,"perimeter_mean":130,"area_mean":1203,"smoothness_mean":0.1096,"compactness_mean":0.1599,"concavity_mean":0.1974,"concave points_mean":0.1279,"symmetry_mean":0.2069,"fractal_dimension_mean":0.05999,"radius_se":0.7456,"texture_se":0.7869,"perimeter_se":4.585,"area_se":94.03,"smoothness_se":0.00615,"compactness_se":0.04006,"concavity_se":0.03832,"concave points_se":0.02058,"symmetry_se":0.0225,"fractal_dimension_se":0.004571,"radius_worst":23.57,"texture_worst":25.53,"perimeter_worst":152.5,"area_worst":1709,"smoothness_worst":0.1444,"compactness_worst":0.4245,"concavity_worst":0.4504,"concave points_worst":0.243,"symmetry_worst":0.3613,"fractal_dimension_worst":0.08758,"Unnamed: 32":null},{"index":3,"id":84348301,"diagnosis":"M","radius_mean":11.42,"texture_mean":20.38,"perimeter_mean":77.58,"area_mean":386.1,"smoothness_mean":0.1425,"compactness_mean":0.2839,"concavity_mean":0.2414,"concave points_mean":0.1052,"symmetry_mean":0.2597,"fractal_dimension_mean":0.09744,"radius_se":0.4956,"texture_se":1.156,"perimeter_se":3.445,"area_se":27.23,"smoothness_se":0.00911,"compactness_se":0.07458,"concavity_se":0.05661,"concave points_se":0.01867,"symmetry_se":0.05963,"fractal_dimension_se":0.009208,"radius_worst":14.91,"texture_worst":26.5,"perimeter_worst":98.87,"area_worst":567.7,"smoothness_worst":0.2098,"compactness_worst":0.8663,"concavity_worst":0.6869,"concave points_worst":0.2575,"symmetry_worst":0.6638,"fractal_dimension_worst":0.173,"Unnamed: 32":null},{"index":4,"id":84358402,"diagnosis":"M","radius_mean":20.29,"texture_mean":14.34,"perimeter_mean":135.1,"area_mean":1297,"smoothness_mean":0.1003,"compactness_mean":0.1328,"concavity_mean":0.198,"concave points_mean":0.1043,"symmetry_mean":0.1809,"fractal_dimension_mean":0.05883,"radius_se":0.7572,"texture_se":0.7813,"perimeter_se":5.438,"area_se":94.44,"smoothness_se":0.01149,"compactness_se":0.02461,"concavity_se":0.05688,"concave points_se":0.01885,"symmetry_se":0.01756,"fractal_dimension_se":0.005115,"radius_worst":22.54,"texture_worst":16.67,"perimeter_worst":152.2,"area_worst":1575,"smoothness_worst":0.1374,"compactness_worst":0.205,"concavity_worst":0.4,"concave points_worst":0.1625,"symmetry_worst":0.2364,"fractal_dimension_worst":0.07678,"Unnamed: 32":null}]},"total_rows":5,"truncation_type":null},"text/plain":"         id diagnosis  ...  fractal_dimension_worst  Unnamed: 32\n0    842302         M  ...                  0.11890          NaN\n1    842517         M  ...                  0.08902          NaN\n2  84300903         M  ...                  0.08758          NaN\n3  84348301         M  ...                  0.17300          NaN\n4  84358402         M  ...                  0.07678          NaN\n\n[5 rows x 33 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>diagnosis</th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>symmetry_mean</th>\n      <th>fractal_dimension_mean</th>\n      <th>radius_se</th>\n      <th>texture_se</th>\n      <th>perimeter_se</th>\n      <th>area_se</th>\n      <th>smoothness_se</th>\n      <th>compactness_se</th>\n      <th>concavity_se</th>\n      <th>concave points_se</th>\n      <th>symmetry_se</th>\n      <th>fractal_dimension_se</th>\n      <th>radius_worst</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n      <th>Unnamed: 32</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>842302</td>\n      <td>M</td>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.3001</td>\n      <td>0.14710</td>\n      <td>0.2419</td>\n      <td>0.07871</td>\n      <td>1.0950</td>\n      <td>0.9053</td>\n      <td>8.589</td>\n      <td>153.40</td>\n      <td>0.006399</td>\n      <td>0.04904</td>\n      <td>0.05373</td>\n      <td>0.01587</td>\n      <td>0.03003</td>\n      <td>0.006193</td>\n      <td>25.38</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.1622</td>\n      <td>0.6656</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>842517</td>\n      <td>M</td>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.0869</td>\n      <td>0.07017</td>\n      <td>0.1812</td>\n      <td>0.05667</td>\n      <td>0.5435</td>\n      <td>0.7339</td>\n      <td>3.398</td>\n      <td>74.08</td>\n      <td>0.005225</td>\n      <td>0.01308</td>\n      <td>0.01860</td>\n      <td>0.01340</td>\n      <td>0.01389</td>\n      <td>0.003532</td>\n      <td>24.99</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.1238</td>\n      <td>0.1866</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>84300903</td>\n      <td>M</td>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.1974</td>\n      <td>0.12790</td>\n      <td>0.2069</td>\n      <td>0.05999</td>\n      <td>0.7456</td>\n      <td>0.7869</td>\n      <td>4.585</td>\n      <td>94.03</td>\n      <td>0.006150</td>\n      <td>0.04006</td>\n      <td>0.03832</td>\n      <td>0.02058</td>\n      <td>0.02250</td>\n      <td>0.004571</td>\n      <td>23.57</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.1444</td>\n      <td>0.4245</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>84348301</td>\n      <td>M</td>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.2414</td>\n      <td>0.10520</td>\n      <td>0.2597</td>\n      <td>0.09744</td>\n      <td>0.4956</td>\n      <td>1.1560</td>\n      <td>3.445</td>\n      <td>27.23</td>\n      <td>0.009110</td>\n      <td>0.07458</td>\n      <td>0.05661</td>\n      <td>0.01867</td>\n      <td>0.05963</td>\n      <td>0.009208</td>\n      <td>14.91</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.2098</td>\n      <td>0.8663</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>84358402</td>\n      <td>M</td>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.1980</td>\n      <td>0.10430</td>\n      <td>0.1809</td>\n      <td>0.05883</td>\n      <td>0.7572</td>\n      <td>0.7813</td>\n      <td>5.438</td>\n      <td>94.44</td>\n      <td>0.011490</td>\n      <td>0.02461</td>\n      <td>0.05688</td>\n      <td>0.01885</td>\n      <td>0.01756</td>\n      <td>0.005115</td>\n      <td>22.54</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.1374</td>\n      <td>0.2050</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"source":"# Import functions to compute accuracy and split data\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n\n# Import models, including VotingClassifier meta-model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier as KNN\nfrom sklearn.ensemble import VotingClassifier\n\n# Set seed for reproducibility\nSEED = 1","metadata":{"executionTime":129,"lastSuccessfullyExecutedCode":"# Import functions to compute accuracy and split data\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n\n# Import models, including VotingClassifier meta-model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier as KNN\nfrom sklearn.ensemble import VotingClassifier\n\n# Set seed for reproducibility\nSEED = 1"},"cell_type":"code","id":"8c50ec4c-8181-45dc-a467-e6a76700c856","execution_count":8,"outputs":[]},{"source":"X = breast_cancer.drop(['diagnosis','Unnamed: 32'],axis=1)\ny = breast_cancer['diagnosis']","metadata":{"executionTime":87,"lastSuccessfullyExecutedCode":"X = breast_cancer.drop(['diagnosis','Unnamed: 32'],axis=1)\ny = breast_cancer['diagnosis']"},"cell_type":"code","id":"7c5a78e9-3c83-4aff-bdb3-e41c126947a7","execution_count":9,"outputs":[]},{"source":"# Split data into 70% train and 30% test\nX_train, X_test, y_train, y_test = train_test_split(X, y,\n                                                   test_size=0.3,\n                                                   random_state=SEED)\n\n# Instantiate individual classifiers\nlr = LogisticRegression(random_state=SEED)\nknn = KNN()\ndt = DecisionTreeClassifier(random_state=SEED)\n\n# Define a list called classifier that contains the tuples (classifier_name, classifier)\nclassifiers = [('Logistic Regression',lr),\n              ('K Nearest Neighbours',knn),\n              ('Classification Tree',dt)]","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# Split data into 70% train and 30% test\nX_train, X_test, y_train, y_test = train_test_split(X, y,\n                                                   test_size=0.3,\n                                                   random_state=SEED)\n\n# Instantiate individual classifiers\nlr = LogisticRegression(random_state=SEED)\nknn = KNN()\ndt = DecisionTreeClassifier(random_state=SEED)\n\n# Define a list called classifier that contains the tuples (classifier_name, classifier)\nclassifiers = [('Logistic Regression',lr),\n              ('K Nearest Neighbours',knn),\n              ('Classification Tree',dt)]"},"cell_type":"code","id":"e2dc1c78-27f2-4a35-94a0-38c682d4ddbd","execution_count":10,"outputs":[]},{"source":"# Iterate over the defined list of tuples containing the classifiers\nfor clf_name, clf in classifiers:\n    #fit clf to the training set\n    clf.fit(X_train, y_train)\n    \n    #Predict the labels of the test set\n    y_pred = clf.predict(X_test)\n    \n    #Evaluate the accuracy of clf on the test set\n    print('{:s} : {:.3f}'.format(clf_name, accuracy_score(y_test, y_pred)))","metadata":{"executionTime":56,"lastSuccessfullyExecutedCode":"# Iterate over the defined list of tuples containing the classifiers\nfor clf_name, clf in classifiers:\n    #fit clf to the training set\n    clf.fit(X_train, y_train)\n    \n    #Predict the labels of the test set\n    y_pred = clf.predict(X_test)\n    \n    #Evaluate the accuracy of clf on the test set\n    print('{:s} : {:.3f}'.format(clf_name, accuracy_score(y_test, y_pred)))"},"cell_type":"code","id":"280e6a3a-d321-426b-ba26-8f67d0045497","execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":"Logistic Regression : 0.632\nK Nearest Neighbours : 0.766\nClassification Tree : 0.930\n"}]},{"source":"# VOTING CLASSIFIER\n\n# Instantiate a VotingClassifier 'vc'\nvc = VotingClassifier(estimators = classifiers)\n\n# Fit 'vc' to the training set and predict test set labels\nvc.fit(X_train, y_train)\ny_pred = vc.predict(X_test)\n\n# Evaluate the test-set accuracy of 'vc'\nprint('Voting Classifier: {:.3f}'.format(accuracy_score(y_test,y_pred)))","metadata":{"executionTime":51,"lastSuccessfullyExecutedCode":"# VOTING CLASSIFIER\n\n# Instantiate a VotingClassifier 'vc'\nvc = VotingClassifier(estimators = classifiers)\n\n# Fit 'vc' to the training set and predict test set labels\nvc.fit(X_train, y_train)\ny_pred = vc.predict(X_test)\n\n# Evaluate the test-set accuracy of 'vc'\nprint('Voting Classifier: {:.3f}'.format(accuracy_score(y_test,y_pred)))"},"cell_type":"code","id":"f398ee19-8b2b-43f4-8d3e-38e0b0fc5309","execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":"Voting Classifier: 0.772\n"}]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataCamp Workspace"},"nbformat":4,"nbformat_minor":5}