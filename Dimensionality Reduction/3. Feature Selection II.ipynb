{"cells":[{"source":"# Feature Selection II - Selecting for Model Accuracy","metadata":{},"cell_type":"markdown","id":"9dd3d688-8783-42a4-a4bf-2877463da449"},{"source":"import pandas as pd\nansur_female = pd.read_csv('datasets/ANSUR_II_FEMALE.csv')\nansur_male = pd.read_csv('datasets/ANSUR_II_MALE.csv')\n\nansur = pd.concat([ansur_female,ansur_male])\nansur.shape","metadata":{"executionTime":157,"lastSuccessfullyExecutedCode":"import pandas as pd\nansur_female = pd.read_csv('datasets/ANSUR_II_FEMALE.csv')\nansur_male = pd.read_csv('datasets/ANSUR_II_MALE.csv')\n\nansur = pd.concat([ansur_female,ansur_male])\nansur.shape"},"cell_type":"code","id":"c9103ca3-663d-4e5c-8683-6ece197db70c","execution_count":1,"outputs":[{"output_type":"execute_result","execution_count":1,"data":{"text/plain":"(6068, 99)"},"metadata":{}}]},{"source":"ansur_filtered = ansur[['Gender','chestdepth','handlength',\n                        'neckcircumference','shoulderlength',\n                       'earlength']]\nansur_filtered.head()","metadata":{"executionTime":160,"lastSuccessfullyExecutedCode":"ansur_filtered = ansur[['Gender','chestdepth','handlength',\n                        'neckcircumference','shoulderlength',\n                       'earlength']]\nansur_filtered.head()"},"cell_type":"code","id":"1bca757e-4bd7-4d49-ac2c-b7fd000444f1","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"application/com.datacamp.data-table.v1+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"Gender","type":"string"},{"name":"chestdepth","type":"integer"},{"name":"handlength","type":"integer"},{"name":"neckcircumference","type":"integer"},{"name":"shoulderlength","type":"integer"},{"name":"earlength","type":"integer"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":[{"index":0,"Gender":"Female","chestdepth":245,"handlength":184,"neckcircumference":335,"shoulderlength":148,"earlength":65},{"index":1,"Gender":"Female","chestdepth":206,"handlength":189,"neckcircumference":302,"shoulderlength":142,"earlength":60},{"index":2,"Gender":"Female","chestdepth":223,"handlength":195,"neckcircumference":325,"shoulderlength":164,"earlength":65},{"index":3,"Gender":"Female","chestdepth":285,"handlength":186,"neckcircumference":357,"shoulderlength":157,"earlength":62},{"index":4,"Gender":"Female","chestdepth":290,"handlength":187,"neckcircumference":340,"shoulderlength":156,"earlength":65}]},"total_rows":5,"truncation_type":null},"text/plain":"   Gender  chestdepth  handlength  neckcircumference  shoulderlength  earlength\n0  Female         245         184                335             148         65\n1  Female         206         189                302             142         60\n2  Female         223         195                325             164         65\n3  Female         285         186                357             157         62\n4  Female         290         187                340             156         65","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Gender</th>\n      <th>chestdepth</th>\n      <th>handlength</th>\n      <th>neckcircumference</th>\n      <th>shoulderlength</th>\n      <th>earlength</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Female</td>\n      <td>245</td>\n      <td>184</td>\n      <td>335</td>\n      <td>148</td>\n      <td>65</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Female</td>\n      <td>206</td>\n      <td>189</td>\n      <td>302</td>\n      <td>142</td>\n      <td>60</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Female</td>\n      <td>223</td>\n      <td>195</td>\n      <td>325</td>\n      <td>164</td>\n      <td>65</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Female</td>\n      <td>285</td>\n      <td>186</td>\n      <td>357</td>\n      <td>157</td>\n      <td>62</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Female</td>\n      <td>290</td>\n      <td>187</td>\n      <td>340</td>\n      <td>156</td>\n      <td>65</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"source":"# Features\nX = ansur_filtered.drop('Gender',axis=1)\n\n# Target\ny = ansur_filtered['Gender']","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# Features\nX = ansur_filtered.drop('Gender',axis=1)\n\n# Target\ny = ansur_filtered['Gender']"},"cell_type":"code","id":"dd8141bc-c553-4f92-81bd-1a00b96debc0","execution_count":3,"outputs":[]},{"source":"# Pre-processing the data\n\n# Split into train-test\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n\n# Standardize the data, mean=0,variance=1\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train_std = scaler.fit_transform(X_train)","metadata":{"executionTime":171,"lastSuccessfullyExecutedCode":"# Pre-processing the data\n\n# Split into train-test\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n\n# Standardize the data, mean=0,variance=1\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train_std = scaler.fit_transform(X_train)"},"cell_type":"code","id":"6a7abf5a-ee7c-4432-b12e-558588c82555","execution_count":4,"outputs":[]},{"source":"# Creating a logistic regression model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\n# Create Logistic regression model and fit using standardized data\nlr = LogisticRegression()\nlr.fit(X_train_std, y_train)\n\n# Calculate accuarcy of the model \nX_test_std = scaler.transform(X_test) #<-- first standardized\n\ny_pred = lr.predict(X_test_std)\nprint(accuracy_score(y_test,y_pred))","metadata":{"executionTime":118,"lastSuccessfullyExecutedCode":"# Creating a logistic regression model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\n# Create Logistic regression model and fit using standardized data\nlr = LogisticRegression()\nlr.fit(X_train_std, y_train)\n\n# Calculate accuarcy of the model \nX_test_std = scaler.transform(X_test) #<-- first standardized\n\ny_pred = lr.predict(X_test_std)\nprint(accuracy_score(y_test,y_pred))"},"cell_type":"code","id":"29cd6d6e-dbde-428f-89f5-9e9a5cd7b837","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":"0.9917627677100495\n"}]},{"source":"# Inspecting the feature coefficients\nprint(lr.coef_)","metadata":{"executionTime":101,"lastSuccessfullyExecutedCode":"# Inspecting the feature coefficients\nprint(lr.coef_)"},"cell_type":"code","id":"b35738f8-ac51-4036-98b1-b28171e3796b","execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":"[[-3.13015988  0.09670542  7.6930968   1.18884854  0.72173223]]\n"}]},{"source":"**Note:** These coefficients will be multiplied with the feature values when the model makes a prediction, features with coefficients close to zero will contribute little to the end result.","metadata":{},"cell_type":"markdown","id":"a1318c8c-d9bb-4225-9bb3-9701d2402dd5"},{"source":"print(dict(zip(X.columns, abs(lr.coef_[0]))))","metadata":{"executionTime":135,"lastSuccessfullyExecutedCode":"print(dict(zip(X.columns, abs(lr.coef_[0]))))"},"cell_type":"code","id":"8e93c322-1e5c-484a-9856-1543bcd7d944","execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":"{'chestdepth': 3.130159883283854, 'handlength': 0.09670541530941415, 'neckcircumference': 7.693096795904505, 'shoulderlength': 1.1888485408523073, 'earlength': 0.7217322335012618}\n"}]},{"source":"# Dropping feature that contribute little to the model\nX.drop('handlength',axis=1, inplace=True)\n\n# Recalculating the accuarcy after dropping a feature\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n\nlr = LogisticRegression()\nlr.fit(scaler.fit_transform(X_train), y_train)\n\nprint(accuracy_score(y_test, lr.predict(scaler.transform(X_test))))","metadata":{"executionTime":336,"lastSuccessfullyExecutedCode":"# Dropping feature that contribute little to the model\nX.drop('handlength',axis=1, inplace=True)\n\n# Recalculating the accuarcy after dropping a feature\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n\nlr = LogisticRegression()\nlr.fit(scaler.fit_transform(X_train), y_train)\n\nprint(accuracy_score(y_test, lr.predict(scaler.transform(X_test))))"},"cell_type":"code","id":"4e38cfb5-c94d-4c9d-a13a-d47666d358f4","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":"0.9862712795167491\n"}]},{"source":"Thus, increased accuracy and decreased model complexity. To repeat this step recursively we have RFE (Recursive Feature Elimination).","metadata":{},"cell_type":"markdown","id":"cd630a3f-2428-4f73-a3ef-93f932d41523"},{"source":"## Recursive Feature Elimination\n- Feature selection algorithm that can be wrapped around any model that produces feature coefficients or feature importance values.\n- We can pass it the model we want to use and the number of features we want to select. \n-  While fitting to our data it will repeat a process where it first fits the internal model and then drops the feature with the weakest coefficient.\n-  It will keep doing this until the desired number of features is reached.","metadata":{},"cell_type":"markdown","id":"502bc7ce-1c6f-42e3-b080-9151cc4909d6"},{"source":"# Features\nX = ansur_filtered.drop('Gender',axis=1)\n\n# Target\ny = ansur_filtered['Gender']","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# Features\nX = ansur_filtered.drop('Gender',axis=1)\n\n# Target\ny = ansur_filtered['Gender']"},"cell_type":"code","id":"940ffe42-ff14-40dc-9205-ac4ce9f64c37","execution_count":9,"outputs":[]},{"source":"# Pre-processing the data\n\n# Split into train-test\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n\n# Standardize the data, mean=0,variance=1\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train_std = scaler.fit_transform(X_train)","metadata":{"executionTime":157,"lastSuccessfullyExecutedCode":"# Pre-processing the data\n\n# Split into train-test\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n\n# Standardize the data, mean=0,variance=1\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train_std = scaler.fit_transform(X_train)"},"cell_type":"code","id":"140505f6-3ff7-4c24-8728-068e5ac41ca9","execution_count":10,"outputs":[]},{"source":"# RFE\nfrom sklearn.feature_selection import RFE\n\n# Instantiate RFE\nrfe = RFE(estimator=LogisticRegression(), n_features_to_select=2, verbose=1)\n\n# Fit the model\nrfe.fit(X_train_std, y_train)","metadata":{"executionTime":132,"lastSuccessfullyExecutedCode":"# RFE\nfrom sklearn.feature_selection import RFE\n\n# Instantiate RFE\nrfe = RFE(estimator=LogisticRegression(), n_features_to_select=2, verbose=1)\n\n# Fit the model\nrfe.fit(X_train_std, y_train)"},"cell_type":"code","id":"e9461fc3-4896-46e0-aff3-12bff2d7f52c","execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":"Fitting estimator with 5 features.\nFitting estimator with 4 features.\nFitting estimator with 3 features.\n"},{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"RFE(estimator=LogisticRegression(), n_features_to_select=2, verbose=1)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RFE(estimator=LogisticRegression(), n_features_to_select=2, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RFE</label><div class=\"sk-toggleable__content\"><pre>RFE(estimator=LogisticRegression(), n_features_to_select=2, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}]},{"source":"# Inspecting the RFE results\nX.columns[rfe.support_]","metadata":{"executionTime":75,"lastSuccessfullyExecutedCode":"# Inspecting the RFE results\nX.columns[rfe.support_]"},"cell_type":"code","id":"22a565c5-b728-4be4-bcba-14c981671c5f","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"Index(['chestdepth', 'neckcircumference'], dtype='object')"},"metadata":{}}]},{"source":"# See in which iteration a feature was dropped\ndict(zip(X.columns, rfe.ranking_))","metadata":{"executionTime":156,"lastSuccessfullyExecutedCode":"# See in which iteration a feature was dropped\ndict(zip(X.columns, rfe.ranking_))"},"cell_type":"code","id":"624c2452-58f6-460a-8af2-b241f0a340cc","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"{'chestdepth': 1,\n 'handlength': 4,\n 'neckcircumference': 1,\n 'shoulderlength': 2,\n 'earlength': 3}"},"metadata":{}}]},{"source":"# Check accuracy from the two remaining feature\nX_test_std = scaler.transform(X_test)\n\naccuracy_score(y_test, rfe.predict(X_test_std))","metadata":{"executionTime":66,"lastSuccessfullyExecutedCode":"# Check accuracy from the two remaining feature\nX_test_std = scaler.transform(X_test)\n\naccuracy_score(y_test, rfe.predict(X_test_std))"},"cell_type":"code","id":"3fe8ac4d-58ef-4161-a330-7c0d564f3707","execution_count":14,"outputs":[{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"0.9802306425041186"},"metadata":{}}]},{"source":"# Tree-based feature selection","metadata":{},"cell_type":"markdown","id":"d2ed7e7e-526e-477a-8b64-0bcfc720b3f4"},{"source":"![image-3](image-3.png)\n\nRandom Forest is one of such models that performs feature selection by design to avoid overfitting. \n- It pass different, random, subsets of features to a number of decision trees.","metadata":{},"cell_type":"markdown","id":"e2051aa5-6a3b-418c-a675-d3cdcf8e1549"},{"source":"import pandas as pd\nansur_female = pd.read_csv('datasets/ANSUR_II_FEMALE.csv')\nansur_male = pd.read_csv('datasets/ANSUR_II_MALE.csv')\n\nansur = pd.concat([ansur_female,ansur_male])\nansur.shape","metadata":{"executionTime":46,"lastSuccessfullyExecutedCode":"import pandas as pd\nansur_female = pd.read_csv('datasets/ANSUR_II_FEMALE.csv')\nansur_male = pd.read_csv('datasets/ANSUR_II_MALE.csv')\n\nansur = pd.concat([ansur_female,ansur_male])\nansur.shape"},"cell_type":"code","id":"4feb352f-8bc2-4ed4-b020-e35f34dbd634","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"(6068, 99)"},"metadata":{}}]},{"source":"ansur.drop(['Branch','Component','BMI_class','Height_class'],\n          axis=1,\n          inplace=True)","metadata":{"executionTime":67,"lastSuccessfullyExecutedCode":"ansur.drop(['Branch','Component','BMI_class','Height_class'],\n          axis=1,\n          inplace=True)"},"cell_type":"code","id":"3eba67c1-22bb-4cbd-97b3-b46a274203bf","execution_count":16,"outputs":[]},{"source":"# Features\nX = ansur.drop('Gender',axis=1)\n\n# Target\ny = ansur['Gender']","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# Features\nX = ansur.drop('Gender',axis=1)\n\n# Target\ny = ansur['Gender']"},"cell_type":"code","id":"10ea2563-76b5-4a59-94e7-ea07b2e4dbec","execution_count":17,"outputs":[]},{"source":"# Split into train-test\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# Split into train-test\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"},"cell_type":"code","id":"9f1f5d1b-3f62-4ed1-90e2-2298a867b5a7","execution_count":18,"outputs":[]},{"source":"# Random forest classifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\nrf = RandomForestClassifier()\n\nrf.fit(X_train, y_train)\n\nprint(accuracy_score(y_test, rf.predict(X_test)))","metadata":{"executionTime":124,"lastSuccessfullyExecutedCode":"# Random forest classifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\nrf = RandomForestClassifier()\n\nrf.fit(X_train, y_train)\n\nprint(accuracy_score(y_test, rf.predict(X_test)))"},"cell_type":"code","id":"fb02e5a0-8c22-48c2-827e-b40abbb15c51","execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":"0.9923119165293794\n"}]},{"source":"Being able to get such high accuracy means it managed to escape the curse of dimensionality and didn't overfit on the many features in the training set.","metadata":{},"cell_type":"markdown","id":"01b58f2f-70b2-45ff-97ca-6b7a6812d431"},{"source":"# Feature importance values\nrf.feature_importances_","metadata":{"executionTime":69,"lastSuccessfullyExecutedCode":"# Feature importance values\nrf.feature_importances_"},"cell_type":"code","id":"ac05ec70-1de5-4a10-86fb-52b0bce2afe8","execution_count":20,"outputs":[{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"array([0.00142133, 0.00109268, 0.00038479, 0.00080267, 0.00355326,\n       0.00621627, 0.00095298, 0.1094743 , 0.00413159, 0.00717979,\n       0.01355828, 0.01857631, 0.0007869 , 0.00510404, 0.00112701,\n       0.01260415, 0.00289644, 0.00072711, 0.00191812, 0.00155842,\n       0.00164152, 0.01178926, 0.0007571 , 0.00166167, 0.00579531,\n       0.01892502, 0.00047618, 0.00635288, 0.00065596, 0.00089918,\n       0.00089665, 0.00194052, 0.00060721, 0.00349696, 0.00141798,\n       0.00260607, 0.0058748 , 0.0218189 , 0.00487626, 0.00067282,\n       0.00050672, 0.02580583, 0.06156871, 0.00084673, 0.00078337,\n       0.00100948, 0.0004952 , 0.04692033, 0.00071765, 0.01632792,\n       0.02435656, 0.0006808 , 0.00076808, 0.00267134, 0.01166292,\n       0.00052644, 0.00033687, 0.00133139, 0.00787438, 0.00543047,\n       0.00135421, 0.16912925, 0.12530706, 0.00510626, 0.00042008,\n       0.00242982, 0.00104707, 0.03809052, 0.00105749, 0.00100116,\n       0.00367124, 0.04459685, 0.00416229, 0.01334964, 0.00136142,\n       0.00152814, 0.00662878, 0.00125006, 0.00059616, 0.0006842 ,\n       0.00049985, 0.00061233, 0.00152926, 0.01942952, 0.00118602,\n       0.00203633, 0.00116945, 0.00108825, 0.00088469, 0.0295487 ,\n       0.00055517, 0.00325857, 0.01443064, 0.00314966])"},"metadata":{}}]},{"source":"An advantage of these feature importance values over coefficients is that they are comparable between features by default, since they always sum up to one.","metadata":{},"cell_type":"markdown","id":"17637d22-408b-4d48-aed4-482ea355160b"},{"source":"# Feature importance as a feature selector\nmask = rf.feature_importances_ > 0.1\nprint(mask)\n\nX_reduced = X.loc[:,mask]\nprint(X_reduced.columns)","metadata":{"executionTime":51,"lastSuccessfullyExecutedCode":"# Feature importance as a feature selector\nmask = rf.feature_importances_ > 0.1\nprint(mask)\n\nX_reduced = X.loc[:,mask]\nprint(X_reduced.columns)"},"cell_type":"code","id":"39cdef9f-55d1-4f67-9912-90918be56c74","execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":"[False False False False False False False  True False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False False False\n False  True  True False False False False False False False False False\n False False False False False False False False False False False False\n False False False False False False False False False False]\nIndex(['biacromialbreadth', 'neckcircumference', 'neckcircumferencebase'], dtype='object')\n"}]},{"source":"# RFE with random forests\nfrom sklearn.feature_selection import RFE\n\n# Model instantiate\nrfe = RFE(estimator=RandomForestClassifier(),\n         n_features_to_select = 6,\n         step = 10, #<-- at each step 10 least imp. features are dropped\n         verbose = 1)\n\n# Fit the model\nrfe.fit(X_train, y_train)\n\n# Remaining features\nprint(X.columns[rfe.support_])","metadata":{"executionTime":8873,"lastSuccessfullyExecutedCode":"# RFE with random forests\nfrom sklearn.feature_selection import RFE\n\n# Model instantiate\nrfe = RFE(estimator=RandomForestClassifier(),\n         n_features_to_select = 6,\n         step = 10, #<-- at each step 10 least imp. features are dropped\n         verbose = 1)\n\n# Fit the model\nrfe.fit(X_train, y_train)\n\n# Remaining features\nprint(X.columns[rfe.support_])"},"cell_type":"code","id":"3585baa7-4e95-4a56-9ae0-1e8f5360bf7a","execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":"Fitting estimator with 94 features.\nFitting estimator with 84 features.\nFitting estimator with 74 features.\nFitting estimator with 64 features.\nFitting estimator with 54 features.\nFitting estimator with 44 features.\nFitting estimator with 34 features.\nFitting estimator with 24 features.\nFitting estimator with 14 features.\nIndex(['biacromialbreadth', 'handcircumference', 'hipbreadthsitting',\n       'neckcircumference', 'neckcircumferencebase', 'shouldercircumference'],\n      dtype='object')\n"}]},{"source":"# accuracy calculation\naccuracy_score(y_test, rfe.predict(X_test))","metadata":{"executionTime":31,"lastSuccessfullyExecutedCode":"# accuracy calculation\naccuracy_score(y_test, rfe.predict(X_test))"},"cell_type":"code","id":"dd4aaae3-2f4c-4e54-a9b7-e1f8efe7777c","execution_count":23,"outputs":[{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"0.9906644700713894"},"metadata":{}}]},{"source":"# Regularized linear regression\n![image-4](image-4.png)\n","metadata":{},"cell_type":"markdown","id":"75ed68b7-c17c-4dc3-906c-f1dfb97db837"},{"source":"ansur_male.drop(['Branch','Component','BMI_class','Height_class','Gender'],\n          axis=1,\n          inplace=True)","metadata":{"executionTime":23,"lastSuccessfullyExecutedCode":"ansur_male.drop(['Branch','Component','BMI_class','Height_class','Gender'],\n          axis=1,\n          inplace=True)"},"cell_type":"code","id":"8f65c920-e15e-4813-9b88-8ecaa5117e5f","execution_count":27,"outputs":[]},{"source":"ansur_male.shape","metadata":{"executionTime":46,"lastSuccessfullyExecutedCode":"ansur_male.shape"},"cell_type":"code","id":"7794e88c-df35-4513-b9d6-bde7ecd7f38f","execution_count":28,"outputs":[{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"(4082, 94)"},"metadata":{}}]},{"source":"X = ansur_male.drop('BMI',axis=1)\ny = ansur_male['BMI']","metadata":{"executionTime":36,"lastSuccessfullyExecutedCode":"X = ansur_male.drop('BMI',axis=1)\ny = ansur_male['BMI']"},"cell_type":"code","id":"8684f43d-e5e6-4482-baa1-327b8b4b37ab","execution_count":29,"outputs":[]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}